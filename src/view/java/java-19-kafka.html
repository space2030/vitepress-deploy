<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>kafka 原理</title>
    <meta name="description" content="VitePress">
    <link rel="stylesheet" href="/vitepress-deploy/assets/style.c6a8f29c.css">
    <link rel="modulepreload" href="/vitepress-deploy/assets/app.2a154df8.js">
    <link rel="modulepreload" href="/vitepress-deploy/assets/src_view_java_java-19-kafka.md.ef7bf4c5.lean.js">
    
    <link rel="icon" href="https://cn.vitejs.dev/logo-with-shadow.png">
  <script>(()=>{const e=localStorage.getItem("vitepress-theme-appearance"),a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-581d5782><!--[--><!--]--><!--[--><span tabindex="-1" data-v-2c02b834></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-2c02b834> Skip to content </a><!--]--><!----><header class="VPNav no-sidebar" data-v-581d5782 data-v-119e663c><div class="VPNavBar" data-v-119e663c data-v-1f7b674d><div class="container" data-v-1f7b674d><div class="VPNavBarTitle" data-v-1f7b674d data-v-ed531ba2><a class="title" href="/vitepress-deploy/" data-v-ed531ba2><!--[--><img class="VPImage logo" src="https://cn.vitejs.dev/logo-with-shadow.png" data-v-81172f9c><!--]--><!--[-->首页<!--]--></a></div><div class="content" data-v-1f7b674d><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-1f7b674d data-v-192c109a><span id="main-nav-aria-label" class="visually-hidden" data-v-192c109a>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/view/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->问答<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/web/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->前端<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/deploy/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->部署<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/kit/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->工具<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/case/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->案例<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-1f7b674d data-v-5cf7609e><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-5cf7609e data-v-766c3cb1 data-v-d6dfd774><span class="check" data-v-d6dfd774><span class="icon" data-v-d6dfd774><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-766c3cb1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-766c3cb1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-1f7b674d data-v-a767cbbe data-v-e03f590e><!--[--><a class="VPSocialLink" href="https://github.com/space2030?tab=repositories" title="github" target="_blank" rel="noopener noreferrer" data-v-e03f590e data-v-3dd9970c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-3dd9970c><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden" data-v-3dd9970c>github</span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-1f7b674d data-v-6a32f7d6 data-v-44cec2e6><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-44cec2e6><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-44cec2e6><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-44cec2e6><div class="VPMenu" data-v-44cec2e6 data-v-ddb22576><!----><!--[--><!--[--><!----><div class="group" data-v-6a32f7d6><div class="item appearance" data-v-6a32f7d6><p class="label" data-v-6a32f7d6>Appearance</p><div class="appearance-action" data-v-6a32f7d6><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-6a32f7d6 data-v-766c3cb1 data-v-d6dfd774><span class="check" data-v-d6dfd774><span class="icon" data-v-d6dfd774><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-766c3cb1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-766c3cb1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-6a32f7d6><div class="item social-links" data-v-6a32f7d6><div class="VPSocialLinks social-links-list" data-v-6a32f7d6 data-v-e03f590e><!--[--><a class="VPSocialLink" href="https://github.com/space2030?tab=repositories" title="github" target="_blank" rel="noopener noreferrer" data-v-e03f590e data-v-3dd9970c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-3dd9970c><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden" data-v-3dd9970c>github</span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-1f7b674d data-v-3524c702><span class="container" data-v-3524c702><span class="top" data-v-3524c702></span><span class="middle" data-v-3524c702></span><span class="bottom" data-v-3524c702></span></span></button></div></div></div><!----></header><!----><!----><div class="VPContent" id="VPContent" data-v-581d5782 data-v-804f35da><div class="VPDoc" data-v-804f35da data-v-3886f8ec><div class="container" data-v-3886f8ec><div class="aside" data-v-3886f8ec><div class="aside-curtain" data-v-3886f8ec></div><div class="aside-container" data-v-3886f8ec><div class="aside-content" data-v-3886f8ec><div class="VPDocAside" data-v-3886f8ec data-v-a4f49d12><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline has-outline" data-v-a4f49d12 data-v-2d325df8><div class="content" data-v-2d325df8><div class="outline-marker" data-v-2d325df8></div><div class="outline-title" data-v-2d325df8>目录</div><nav aria-labelledby="doc-outline-aria-label" data-v-2d325df8><span class="visually-hidden" id="doc-outline-aria-label" data-v-2d325df8> Table of Contents for current page </span><ul class="root" data-v-2d325df8><!--[--><li style="" data-v-2d325df8><a class="outline-link" href="#_01-kafka-设计" data-v-2d325df8>01 kafka 设计</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_02-数据传输的事务定义有哪三种" data-v-2d325df8>02 数据传输的事务定义有哪三种</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_03-kafka判断一个节点是否还活着有哪两个条件？" data-v-2d325df8>03 kafka判断一个节点是否还活着有哪两个条件？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_04-producer是否直接将数据发送到broker的leader节点？" data-v-2d325df8>04 producer是否直接将数据发送到broker的leader节点？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_05-kafka-consumer是否可以消费指定分区消息" data-v-2d325df8>05 kafka  consumer是否可以消费指定分区消息</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_06-kafka消息是采用pull模式，还是push模式？" data-v-2d325df8>06 kafka消息是采用pull模式，还是push模式？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_07-kafka存储在硬盘上的消息格式" data-v-2d325df8>07 kafka存储在硬盘上的消息格式</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_08-kafka高效文件存储设计" data-v-2d325df8>08 kafka高效文件存储设计</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_09-kafka与传统消息之间三个区别" data-v-2d325df8>09 kafka与传统消息之间三个区别</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_10-kafka创建topic时如何将分区放置到不同的broker中？" data-v-2d325df8>10 kafka创建topic时如何将分区放置到不同的broker中？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_11-kafka新建的分区会在哪个目录下创建" data-v-2d325df8>11 kafka新建的分区会在哪个目录下创建</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_12-partition的数据如何保持到硬盘" data-v-2d325df8>12 partition的数据如何保持到硬盘</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_13-kafka的ack机制" data-v-2d325df8>13 kafka的ack机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_14-kafka的消费者如何消费数据" data-v-2d325df8>14 kafka的消费者如何消费数据</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_15-消费者负载均衡策略" data-v-2d325df8>15 消费者负载均衡策略</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_16-数据有序" data-v-2d325df8>16 数据有序</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_17-kafka生产数据时数据的分组策略" data-v-2d325df8>17 kafka生产数据时数据的分组策略</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_18-如何获取topic主题列表" data-v-2d325df8>18 如何获取topic主题列表</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_19-kafka维护消费状态跟踪的方法" data-v-2d325df8>19 kafka维护消费状态跟踪的方法</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_20-消息系统" data-v-2d325df8>20 消息系统</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_21-zk对kafka的作用" data-v-2d325df8>21 zk对kafka的作用</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_22-kafka判断一个节点是否还活着有哪两个条件" data-v-2d325df8>22 kafka判断一个节点是否还活着有哪两个条件</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_23-kafka与传统mq区别" data-v-2d325df8>23 kafka与传统mq区别</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_24-消费者故障，出现活锁问题" data-v-2d325df8>24 消费者故障，出现活锁问题</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_25-如何控制消费的位置" data-v-2d325df8>25 如何控制消费的位置</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_26-kafka保证消息的顺序消费" data-v-2d325df8>26 kafka保证消息的顺序消费</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_27-kafka保证不重复消费" data-v-2d325df8>27 kafka保证不重复消费</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_28-kafka中位移（offset）的作用" data-v-2d325df8>28 kafka中位移（offset）的作用</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_29-kafka中领导者副本（leader-replica）和追随者副本（follower-replica）的区别" data-v-2d325df8>29 kafka中领导者副本（leader replica）和追随者副本（Follower replica）的区别</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_30-kafka参数" data-v-2d325df8>30 kafka参数</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_31-kafka能手动删除消息吗" data-v-2d325df8>31 kafka能手动删除消息吗</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_32-分区leader选举策略" data-v-2d325df8>32 分区Leader选举策略</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_33-kafka零拷贝场景" data-v-2d325df8>33 kafka零拷贝场景</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_34-kafka为什么不支持读写分离" data-v-2d325df8>34 kafka为什么不支持读写分离</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_35-kafka调优" data-v-2d325df8>35 kafka调优</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_36-controller发生网络分区对kafka的影响" data-v-2d325df8>36 Controller发生网络分区对kafka的影响</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_37-consumer采用单线程来获取消息原因" data-v-2d325df8>37 Consumer采用单线程来获取消息原因</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_38-follower副本消息同步的完整流程" data-v-2d325df8>38 follower副本消息同步的完整流程</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_39-kafka中有哪些组件" data-v-2d325df8>39 kafka中有哪些组件</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_40-ack机制" data-v-2d325df8>40 ack机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_41-kafka什么情况下会rebalance" data-v-2d325df8>41 kafka什么情况下会rebalance</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_42-rebalance影响" data-v-2d325df8>42 rebalance影响</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_43-如何解决rebalance问题" data-v-2d325df8>43 如何解决rebalance问题</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_44-kafka为何快" data-v-2d325df8>44 kafka为何快</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_45-kafka" data-v-2d325df8>45 kafka</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_46-kafka-vs-zookeeper" data-v-2d325df8>46 kafka vs zookeeper</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_47-isr、ar、osr" data-v-2d325df8>47 ISR、AR、OSR</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_48-follower如何与leader同步数据" data-v-2d325df8>48 follower如何与leader同步数据</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_49-kafka-可以脱离-zookeeper-单独使用吗？" data-v-2d325df8>49 kafka 可以脱离 zookeeper 单独使用吗？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_50-kafka-有几种数据保留的策略？" data-v-2d325df8>50 kafka 有几种数据保留的策略？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_51-kafka-同时设置了-7-天和-10g-清除数据，到第五天的时候消息达到了-10g，这个时候-kafka-将如何处理？" data-v-2d325df8>51 kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_52-什么情况会导致-kafka-运行变慢？" data-v-2d325df8>52 什么情况会导致 kafka 运行变慢？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_53-使用-kafka-集群需要注意什么？" data-v-2d325df8>53 使用 kafka 集群需要注意什么？</a><!----></li><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-a4f49d12></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-3886f8ec><div class="content-container" data-v-3886f8ec><!--[--><!--]--><main class="main" data-v-3886f8ec><div style="position:relative;" class="vp-doc _vitepress-deploy_src_view_java_java-19-kafka" data-v-3886f8ec><div><h1 id="kafka-原理" tabindex="-1">kafka 原理 <a class="header-anchor" href="#kafka-原理" aria-hidden="true">#</a></h1><h2 id="_01-kafka-设计" tabindex="-1">01 kafka 设计 <a class="header-anchor" href="#_01-kafka-设计" aria-hidden="true">#</a></h2><ol><li>kafaka将消息以topic为单位进行归纳</li><li>将向kafaka topic发布消息的程序成为producers</li><li>将预定topic并消费消息的程序成为consumer</li><li>kafka以集群的方式运行，可由一个或多个服务组成，每个服务叫做一个broker，producers通过网络将消息发送到kafka集群，集群向消费者提供消息</li></ol><h2 id="_02-数据传输的事务定义有哪三种" tabindex="-1">02 数据传输的事务定义有哪三种 <a class="header-anchor" href="#_02-数据传输的事务定义有哪三种" aria-hidden="true">#</a></h2><ol><li>最多一次：消息不会被重复发送，最多被传输一次，但也有可能一次不传输</li><li>最少一次：消息不会被漏发送，最少被出传输一次，但也有可能被重复传输</li><li>精确的一次：不会漏传输也不会重复传输，每个消息都传输被一次而且仅仅被传输一次</li></ol><h2 id="_03-kafka判断一个节点是否还活着有哪两个条件？" tabindex="-1">03 kafka判断一个节点是否还活着有哪两个条件？ <a class="header-anchor" href="#_03-kafka判断一个节点是否还活着有哪两个条件？" aria-hidden="true">#</a></h2><ul><li>节点必须可以维护和zk的连接，zk通过心跳机制检查每个节点的连接</li><li>如果节点是个follower，它必须能及时同步leader的写操作，延时不能太久</li></ul><h2 id="_04-producer是否直接将数据发送到broker的leader节点？" tabindex="-1">04 producer是否直接将数据发送到broker的leader节点？ <a class="header-anchor" href="#_04-producer是否直接将数据发送到broker的leader节点？" aria-hidden="true">#</a></h2><p>producer直接将数据发送到broker的leader主节点，不需要在多个节点进行分发， 为了帮住producer做到这点，所有的kafaka都可以及时的告知： 哪些节点是活动的，目标topic目标分区的leader在哪，这样producer就可以直接将消息发送到目的地了</p><h2 id="_05-kafka-consumer是否可以消费指定分区消息" tabindex="-1">05 kafka consumer是否可以消费指定分区消息 <a class="header-anchor" href="#_05-kafka-consumer是否可以消费指定分区消息" aria-hidden="true">#</a></h2><p>kafka consumer 消费消息时，向broker发出“fetch”请求去消费特定分区的消息， consumer指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息， customer拥有了offset的控制权，可向后回滚去重新消费之前的消息</p><h2 id="_06-kafka消息是采用pull模式，还是push模式？" tabindex="-1">06 kafka消息是采用pull模式，还是push模式？ <a class="header-anchor" href="#_06-kafka消息是采用pull模式，还是push模式？" aria-hidden="true">#</a></h2><ol><li>kafka遵循一种大部分消息系统共同的传统设计：producer将消息推送到broker，consumer从broker拉取消息</li><li>kafka选取传统pull模式</li><li>pull模式的好处是consumer可自主决定是否批量的从broker拉取数据，push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送，如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费</li><li>pull模式缺点：如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达，为了避免这点，kafka有个参数可让consumer阻塞直到新消息到达，也可以阻塞知道消息的数量达到某个特定的量这样可以批量发</li></ol><h2 id="_07-kafka存储在硬盘上的消息格式" tabindex="-1">07 kafka存储在硬盘上的消息格式 <a class="header-anchor" href="#_07-kafka存储在硬盘上的消息格式" aria-hidden="true">#</a></h2><p>消息由一个固定长度的头部和可变长度的字节数组组成，头部包含了一个版本号和CRC32校验码</p><ul><li>a. 消息长度：4byte</li><li>b. 版本号：1byte</li><li>c. CRC校验码：4byte</li><li>d. 具体的消息：nbyte</li></ul><h2 id="_08-kafka高效文件存储设计" tabindex="-1">08 kafka高效文件存储设计 <a class="header-anchor" href="#_08-kafka高效文件存储设计" aria-hidden="true">#</a></h2><ol><li>kafka把topic中一个partition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用</li><li>通过索引信息可快速定位message和确定response的最大大小</li><li>通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作</li><li>通过索引文件稀疏存储，可大幅降低index文件元数据空间大小</li></ol><h2 id="_09-kafka与传统消息之间三个区别" tabindex="-1">09 kafka与传统消息之间三个区别 <a class="header-anchor" href="#_09-kafka与传统消息之间三个区别" aria-hidden="true">#</a></h2><ol><li>kafka持久化日志，这些日志可被重复读取和无限期保留</li><li>kafka是一个分布式系统，它以集群方式运行，可灵活伸缩，在内部通过复制数据提升容错能力和高可用性</li><li>kafka支持实时的流式处理</li></ol><h2 id="_10-kafka创建topic时如何将分区放置到不同的broker中？" tabindex="-1">10 kafka创建topic时如何将分区放置到不同的broker中？ <a class="header-anchor" href="#_10-kafka创建topic时如何将分区放置到不同的broker中？" aria-hidden="true">#</a></h2><ol><li>副本因子不能大于broker的个数</li><li>第一个分区的第一个副本放置位置是随机从brokerList选择的</li><li>其它分区的第一个副本放置位置相对于第0个分区依次往后移，也就是我们有5个broker，5个分区，假设第一个分区放在第四个broker上，那么第二个分区将会放在第五个broker上，第三个分区将会放在第一个broker上，第四个分区将会放在第二个broker上，依次类推。</li><li>剩余的副本相对于第一个副本放置位置其实是由nextReplicaShift决定的，而这个数是随机产生的</li></ol><h2 id="_11-kafka新建的分区会在哪个目录下创建" tabindex="-1">11 kafka新建的分区会在哪个目录下创建 <a class="header-anchor" href="#_11-kafka新建的分区会在哪个目录下创建" aria-hidden="true">#</a></h2><ul><li>在启动kafka集群之前，我们需要配置好log.dirs参数，其值是kafka数据的存放目录，</li><li>这个参数可配置多个目录，目录之间使用逗号分隔，通常这些目录是分布在不同的磁盘上，用于提高读写性能</li><li><strong>如果log.dirs参数只配置了多个目录，那么kafka会在哪个文件夹中创建分区目录呢</strong><ul><li>a. kafka会在含有分区目录最少的文件夹中创建新的分区目录，分区目录名为topic名+分区ID</li><li>b. 是在分区目录最少的文件夹，不是磁盘使用量最少的目录</li><li>c. 如果你给log.dirs参数新增了一个新的磁盘，新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止。</li></ul></li></ul><h2 id="_12-partition的数据如何保持到硬盘" tabindex="-1">12 partition的数据如何保持到硬盘 <a class="header-anchor" href="#_12-partition的数据如何保持到硬盘" aria-hidden="true">#</a></h2><ol><li>topic中的多个partition以文件夹的形式保存到broker，每个分区序号从0递增且消息有序</li><li>partition文件下有多个segment</li><li>segment文件里的大小和配置文件大小一致，可根据要求修改默认1G</li><li>如果大小小于1G时，会滚动一个新的segment并且以上一个segment最后一条消息的偏移量命名</li></ol><h2 id="_13-kafka的ack机制" tabindex="-1">13 kafka的ack机制 <a class="header-anchor" href="#_13-kafka的ack机制" aria-hidden="true">#</a></h2><p>request.required.acks有三个值0、1、-1</p><ul><li>a. 0：生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱当server挂掉的时候就会丢失数据</li><li>b. 1：服务端会等待ack值leader副本确认接收到消息后发送ack但是如果leader挂掉后它不确保是否复制完成，新leader也会导致数据丢失</li><li>c. -1：同样在1基础上服务端会等所有的follower的副本受到leader发出的ack，这样数据不会丢失</li></ul><h2 id="_14-kafka的消费者如何消费数据" tabindex="-1">14 kafka的消费者如何消费数据 <a class="header-anchor" href="#_14-kafka的消费者如何消费数据" aria-hidden="true">#</a></h2><p>消费者每次消费数据的时候，消费者都会记录消费的物理偏移量（offset）的位置， 等到下次消费时，它会接着上次位置继续消费</p><h2 id="_15-消费者负载均衡策略" tabindex="-1">15 消费者负载均衡策略 <a class="header-anchor" href="#_15-消费者负载均衡策略" aria-hidden="true">#</a></h2><p>一个消费者组中的一个分片对应一个消费者成员，它能保证每个消费成员都能访问，如果组中成员太多会有空闲的成员</p><h2 id="_16-数据有序" tabindex="-1">16 数据有序 <a class="header-anchor" href="#_16-数据有序" aria-hidden="true">#</a></h2><p>一个消费者组里它的内部是有序的，消费者组与消费者组之间是无序的</p><h2 id="_17-kafka生产数据时数据的分组策略" tabindex="-1">17 kafka生产数据时数据的分组策略 <a class="header-anchor" href="#_17-kafka生产数据时数据的分组策略" aria-hidden="true">#</a></h2><ol><li>生产者决定数据产生到集群的哪个partition中</li><li>每一条消息都是以（key，value）格式</li><li>key是由生产者发送数据传入</li><li>生产者（key）决定了数据产生到集群的哪个partition</li></ol><h2 id="_18-如何获取topic主题列表" tabindex="-1">18 如何获取topic主题列表 <a class="header-anchor" href="#_18-如何获取topic主题列表" aria-hidden="true">#</a></h2><div class="language-shell"><span class="copy"></span><pre><code><span class="line"><span style="color:#C9D1D9;">bin/kafka-topic.sh  --list  --zookeeper  localhost:2181</span></span>
<span class="line"></span></code></pre></div><h2 id="_19-kafka维护消费状态跟踪的方法" tabindex="-1">19 kafka维护消费状态跟踪的方法 <a class="header-anchor" href="#_19-kafka维护消费状态跟踪的方法" aria-hidden="true">#</a></h2><ol><li>大部分消息系统在broker端的维护消息被消费的记录：一个消息被分发到consumer后broker就马上进行标记或者等待customer的通知后进行标记，这样可以在消费后立马就删除以减少空间占用</li><li>如果一个消息发送出去之后就立即被标记为消费过，一旦consumer处理消息失败了（比如程序崩溃）消息就丢失了</li></ol><ul><li>为了解决这个问题，很多消息系统提供了另外一个功能：当消息被发送出去之后，仅仅标记为已发送状态，当接到consumer已经消费成功的通知后才标记为已消费的状态，这虽然解决了消息丢失的问题，但产生了新的问题：</li><li>首先，consumer处理消息成功了但是向broker发送响应时失败了，这条消息将被消费两次</li><li>第二个问题，broker必须维护每条消息的状态，并且每次都要先锁住消息然后更改状态然后释放锁，会导致消息发送出去但没有收到消费成功的通知，这条消息将一直处于被锁定的状态</li></ul><ol start="3"><li>kafka采用不同的策略，topic被分成若干分区，每个分区在同一时间只被一个consumer消费，这意味着每个分区被消费的消息在日志中的位置仅仅是一个简单的整数：offset，这样就很容易标记每个分区消费状态就很容易了</li><li>consumer可以把offset调成一个较老的值，去重新消费的消息，这对传统的消息系统来说看起来有些不可思议，但确实是非常有用的，谁规定了一条消息只能被消费一次呢？</li></ol><h2 id="_20-消息系统" tabindex="-1">20 消息系统 <a class="header-anchor" href="#_20-消息系统" aria-hidden="true">#</a></h2><ol><li>解耦：允许独立的扩展或修改两边的处理过程</li><li>冗余：消息队列把数据进行持久化直到它们已经被完全处理</li><li>扩展性：因为消息队列解耦了你的处理过程，增大消息入队和处理的频率是很容易</li><li>峰值处理能力</li><li>可恢复性</li><li>顺序保证</li><li>缓冲</li><li>异步通信</li></ol><h2 id="_21-zk对kafka的作用" tabindex="-1">21 zk对kafka的作用 <a class="header-anchor" href="#_21-zk对kafka的作用" aria-hidden="true">#</a></h2><ol><li>zk是开放源码的、高性能协调服务，它用于kafka的分布式应用</li><li>zk主要用于集群中不同节点之间进行通信</li><li>kafka中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取</li><li>其他作用：leader检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态</li></ol><h2 id="_22-kafka判断一个节点是否还活着有哪两个条件" tabindex="-1">22 kafka判断一个节点是否还活着有哪两个条件 <a class="header-anchor" href="#_22-kafka判断一个节点是否还活着有哪两个条件" aria-hidden="true">#</a></h2><ul><li>节点必须可维护和zk的连接，zk通过心跳机制检查每个节点的连接</li><li>节点是个follower，它必须能及时的同时leader的写操作，延时不能太久</li></ul><h2 id="_23-kafka与传统mq区别" tabindex="-1">23 kafka与传统mq区别 <a class="header-anchor" href="#_23-kafka与传统mq区别" aria-hidden="true">#</a></h2><ol><li>kafka持久化日志，这些日志可被重复读取和无限期保留</li><li>kafka是分布式系统，它以集群的方式运行，可灵活伸缩，在内部通过复制数据提升容错能力和高可用性</li><li>kafka支持实时的流式处理</li></ol><h2 id="_24-消费者故障，出现活锁问题" tabindex="-1">24 消费者故障，出现活锁问题 <a class="header-anchor" href="#_24-消费者故障，出现活锁问题" aria-hidden="true">#</a></h2><ol><li>出现“活锁”的情况，是它持续的发送心跳，但是没有处理，为了预防消费者在这种情况下一直持有分区，使用max.poll.interval.ms活跃检测机制，在此基础上，如果你调用的poll频率大于最大间隔，则客户端将主动离开组，以便其他消费者接管该分区</li><li>发生这种情况时，你会看到offset提交失败（调用commitSync()引发的CommitFailedException）这是一种安全机制，保障只有活动成员能够提交offset，要留在组中，你必须持续调用poll</li><li>消费者提供两个配置设置来控制poll循环 <ul><li>a. <a href="http://max.poll.interval.ms" target="_blank" rel="noopener noreferrer">max.poll.interval.ms</a>：增大poll的间隔，可为消费者提供更多的时间去处理返回的消息（调用poll（long）返回的消息，通常返回的消息都是一批）缺点是此值越大将会延迟组重新平衡</li><li>b. max.poll.records：此设置限制每次调用poll返回的消息数，这样可预测每次poll间隔要处理的最大值，通过调整此值，可减少poll间隔，减少重新平衡分组的</li><li>c. 对于消息处理时间不可预测地的情况，这些选项是不够的，处理这种情况的推荐方法是将消息处理移到另一个线程中，让消费者继续调用poll，但是必须注意确保已提交的offset不超过实际位置，另外你必须禁用自动提交，并只有在线程完成处理后才为记录手动提交偏移量（取决于你）。还要注意，你需要pause暂停分区，不会从poll接收到新消息，让线程处理完之前返回的消息（如果你的处理能力比拉取消息的慢，那创建新线程将导致你机器内存溢出）。</li></ul></li></ol><h2 id="_25-如何控制消费的位置" tabindex="-1">25 如何控制消费的位置 <a class="header-anchor" href="#_25-如何控制消费的位置" aria-hidden="true">#</a></h2><p>kafka使用“seek（TopicPartition , long）”指定新的消费位置， 用于查找服务器保留的最早和最新的offset的特殊方法 可用“seekToBeginning(Collection)”和“seekToEnd(Collection)”</p><h2 id="_26-kafka保证消息的顺序消费" tabindex="-1">26 kafka保证消息的顺序消费 <a class="header-anchor" href="#_26-kafka保证消息的顺序消费" aria-hidden="true">#</a></h2><ul><li>kafka分布式的单位是partition，同一个partition用一个write ahead log，所以可保证FIFO的顺序，不同partition之间不能保证顺序，但是绝大多数用户都可通过message key定义，因为同一个key的message可以保证只发送到同一个partition</li><li>kafka中发送1条消息的时候，可指定（topic、partition、key）3个参数，partition和key是可选的，如果你指定了partition，那就是所以消息发往同一个partition，并且在消费端kafka保证，1个partition只能被1个consumer消费，或者你指定key（比如 order id），具有同1个key的所有消息，会发往同一个partition</li></ul><h2 id="_27-kafka保证不重复消费" tabindex="-1">27 kafka保证不重复消费 <a class="header-anchor" href="#_27-kafka保证不重复消费" aria-hidden="true">#</a></h2><ol><li>数据写库操作，先根据主键查一下，如果这数据都有了，你就别插入了，update一下</li><li>写redis，每次都是set，set保证不重复</li><li>让生产者发送每条数据的时候，里面加一个全局唯一的id，消费到了之后，先根据这个id去redis查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写Redis，如果消费过了，你就别处理了</li></ol><h2 id="_28-kafka中位移（offset）的作用" tabindex="-1">28 kafka中位移（offset）的作用 <a class="header-anchor" href="#_28-kafka中位移（offset）的作用" aria-hidden="true">#</a></h2><ul><li>kafka中，每个主题分区下的每条消息都被赋予了一个唯一的ID数值，</li><li>用于标识它在分区中的位置，这个ID数值，称为位移</li><li>一旦消息被写入到分区日志，它的位移值就不能被修改</li></ul><h2 id="_29-kafka中领导者副本（leader-replica）和追随者副本（follower-replica）的区别" tabindex="-1">29 kafka中领导者副本（leader replica）和追随者副本（Follower replica）的区别 <a class="header-anchor" href="#_29-kafka中领导者副本（leader-replica）和追随者副本（follower-replica）的区别" aria-hidden="true">#</a></h2><ol><li>kafka副本当前分为领导者副本和追随者副本，只有leader副本才能对外提供读写服务，响应clients端的请求</li><li>follower副本只是采用pull的方式，被动地同步leader副本中数据，并且在leader副本所在的broker宕机后，随时准备应聘leader副本</li><li>follower副本也能对外提供读服务，自kafka 2.4版本开始</li><li>强调leader和follower的消息序列在实例场景中不一致，很多因素可造成leader和follower之间不同步，比如程序问题、网络问题、broker问题，短暂的不同步我们可关注（秒级别），但长时间的不同步可能需要深入排查，一旦leader所在节点异常，可直接影响可用性</li></ol><h2 id="_30-kafka参数" tabindex="-1">30 kafka参数 <a class="header-anchor" href="#_30-kafka参数" aria-hidden="true">#</a></h2><div class="language-shell"><span class="copy"></span><pre><code><span class="line"><span style="color:#8B949E;"># broker端参数</span></span>
<span class="line"><span style="color:#C9D1D9;">a. message.max.bytes</span></span>
<span class="line"><span style="color:#C9D1D9;">b. max.message.bytes(topic级别)</span></span>
<span class="line"><span style="color:#C9D1D9;">c. replica.fetch.max.bytes(否则follow会同步失败)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#8B949E;"># consumer参数</span></span>
<span class="line"><span style="color:#C9D1D9;">a. fetch.message.max.bytes</span></span>
<span class="line"></span></code></pre></div><h2 id="_31-kafka能手动删除消息吗" tabindex="-1">31 kafka能手动删除消息吗 <a class="header-anchor" href="#_31-kafka能手动删除消息吗" aria-hidden="true">#</a></h2><ol><li>kafka不需要用户手动删除消息，它本身提供了留存数据，能够自动删除过期消息，当然，它是支持手动删除消息的</li><li>对于设置了key且参数cleanup.policy=compact的主题，我们可构造一条消息发送给broker，依靠Log cleaner组件提供的功能删除掉该key的消息</li><li>对于普通主题而言，可使用kafka-delete-records命令，或编写程序调用admin.deleteRecords方法来删除消息，这两种方法殊途同归，底层都是admin.deleteRecords方法，通过将分区long start offset值抬高的方式间接删除消息。</li></ol><h2 id="_32-分区leader选举策略" tabindex="-1">32 分区Leader选举策略 <a class="header-anchor" href="#_32-分区leader选举策略" aria-hidden="true">#</a></h2><ol><li>OfflinePartition Leader选举：每当有分区上线时，就需要执行Leader选举，所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线</li><li>ReassignPartition Leader选举：当你手动运行kafka-reassign-partitions命令，或者调用admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举，假设原来的AR是[1,2,3]，leader是1，当执行副本数量重分配后，副本集合AR被设置成[4，5，6]，leader必须变更，此时会发生reassign partition leader选举</li><li>preferredReplicaPartition Leader选举：当你手动运行kafka-preferred-replica-election命令，或自动触发了preferred leader选举时，该类策略被激活，所谓的preferred leader，指的是AR中第一个副本，比如AR是[1，2，3]，那么preferred leader就是3</li><li>controlledShutdownPartition leader选举：当broker正常关闭时，该broker上所有的leader副本都会下线，因此，需要为受影响的分区执行相应的leader选举</li></ol><h2 id="_33-kafka零拷贝场景" tabindex="-1">33 kafka零拷贝场景 <a class="header-anchor" href="#_33-kafka零拷贝场景" aria-hidden="true">#</a></h2><p>基于mmap的索引和日志文件读写所用的transportLayer</p><div class="tip custom-block"><p class="custom-block-title">基于mmap的索引</p><p>索引都是基于mappedByteBuffer的，也就是说让用户态和内核态共享内核态的数据缓冲区，此时数据不需要复制用户态空间，不过，mmap虽然避免不必要的拷贝，但不一定就保证很高的性能，在不同的操作系统下，mmap的创建和销毁成本可能是不一样的，很高的创建和销毁会抵消zero copy带来的性能优势，由于这种不确定性，在kafka中，只有索引应用了mmap，最核心的日志并未使用mmap机制</p></div><div class="tip custom-block"><p class="custom-block-title">transportLayer是kafka传输层的接口</p><p>它是某个实现类使用了FileChannel的transferTo方法，该方法底层使用了sendfile实现了zero copy，对于kafka而言，如果I/O通道使用普通的planintext，那么kafka就可以利用zero copy特性，直接将页面缓存中的数据发送到网卡的buffer中，避免中间的多次拷贝，相反，如果I/O通道启用了SSL，那么kafka便无法利用zero copy特性</p></div><h2 id="_34-kafka为什么不支持读写分离" tabindex="-1">34 kafka为什么不支持读写分离 <a class="header-anchor" href="#_34-kafka为什么不支持读写分离" aria-hidden="true">#</a></h2><ol><li>如果支持读写分离，那其实对于一致性的要求可能就会有一定的折扣，因为通常的场景下，副本之间都是通过同步来实现副本数据一致的，那同步过程中肯定会有时间的消耗，如果支持了读写分离，就意味着可能会发生数据不一致，或者数据滞后。</li><li>leader/follower模型并没有规定follower副本不可对外提供读服务，kafka最初为了避免不一致性的问题，而采用了让leader统一提供服务的方式</li><li>自kafka2.4之后，kafka提供了有限度的读写分离，follower副本能够对外提供读服务。</li></ol><h2 id="_35-kafka调优" tabindex="-1">35 kafka调优 <a class="header-anchor" href="#_35-kafka调优" aria-hidden="true">#</a></h2><ol><li>调优方向：吞吐量、延时、持久性、可用性。</li><li>如优化kafka的TPS <ul><li>a. Producer端：<a href="http://xn--batch-e86h117a.xn--sizelinger-kh7q.ms" target="_blank" rel="noopener noreferrer">增加batch.size和linger.ms</a>，启动压缩，关闭重试</li><li>b. Broker端：增加num.replica.fetchers提升Follower同步TPS，避免Broker Full GC等</li><li>c. Consumer：增加fetch.min.bytes</li></ul></li></ol><h2 id="_36-controller发生网络分区对kafka的影响" tabindex="-1">36 Controller发生网络分区对kafka的影响 <a class="header-anchor" href="#_36-controller发生网络分区对kafka的影响" aria-hidden="true">#</a></h2><ol><li>一旦发生Controlller网络分区，第一要务就是查看集群是否出现“脑裂”，即同时出现两个甚至是多个Controller组件，这可以根据Broker端监控指标ActiveControllerCount来判断。</li><li>不过，通常我们在设计整个部署架构时，为了避免这种网络分区的发生，一般会将broker节点尽可能的放置在一个机房或者可用区</li><li>由于Controller会给Broker发送3类请求，LeaderAndIsrRequest、StopReplicaRequest、UpdateMetadataRequest，因此一旦出现网络分区，这些请求将不能顺利到达Broker端</li><li>将影响主题的创建、修改、删除操作的信息同步，表现为集群仿佛僵住了，无法感知到后面的所有操作</li></ol><h2 id="_37-consumer采用单线程来获取消息原因" tabindex="-1">37 Consumer采用单线程来获取消息原因 <a class="header-anchor" href="#_37-consumer采用单线程来获取消息原因" aria-hidden="true">#</a></h2><ul><li>Java Consumer是双线程的设计，一个线程是用户的主线程，负责获取消息，另一个是线程是心跳线程，负责向kafka汇报消费者存活情况，将心跳单独放入专属的线程，能够有效地规避因为消息处理速度慢而被视为下线的“假死”情况</li><li>单线程获取消息的设计能够避免阻塞式的消息获取方式，单线程轮询方式容易实现异步非阻塞式，这便于消费者扩展成支持实时流处理的操作算子，操作算子是不能阻塞的</li></ul><h2 id="_38-follower副本消息同步的完整流程" tabindex="-1">38 follower副本消息同步的完整流程 <a class="header-anchor" href="#_38-follower副本消息同步的完整流程" aria-hidden="true">#</a></h2><ol><li>follower发送fetch请求给leader</li><li>leader会读取底层日志文件中的消息数据，再更新它内存中的follower副本的leo值，更新为fetch请求中的fetchOffset值</li><li>尝试更新分区高水位值，follower接收到fetch响应之后，会把消息写入到底层日志，接着更新leo和hw值</li><li>leader和follower的hw值更新时机是不同的，follower的hw更新永远落后于leader的hw，这种时间上错配是造成各种不一致的原因</li><li>对于消费者而言，消费到的消息永远是所有副本中最小的那个hw</li></ol><h2 id="_39-kafka中有哪些组件" tabindex="-1">39 kafka中有哪些组件 <a class="header-anchor" href="#_39-kafka中有哪些组件" aria-hidden="true">#</a></h2><ol><li>主题：kafka主题是一堆或一组消息</li><li>生产者：在kafka，生产者发布通信以及向kafka主题发布消息</li><li>消费者：kafka消费者订阅了一个主题，并且还从主题中读取和处理消息</li><li>经纪人：在管理主题中的消息存储时，我们使用kafka brokers</li></ol><h2 id="_40-ack机制" tabindex="-1">40 ack机制 <a class="header-anchor" href="#_40-ack机制" aria-hidden="true">#</a></h2><ul><li>0：producer无需等待leader的确认（吞吐量高、数据可靠性最差）</li><li>1：代表需要leader确认写入它的本地log并立即确认</li><li>-1/all：代表所有的ISR都完成后确认（吞吐量最低，数据可靠性最高）</li></ul><h2 id="_41-kafka什么情况下会rebalance" tabindex="-1">41 kafka什么情况下会rebalance <a class="header-anchor" href="#_41-kafka什么情况下会rebalance" aria-hidden="true">#</a></h2><div class="tip custom-block"><p class="custom-block-title">rebalance的触发条件有五个：</p><ul><li>a. 有新的consumer加入</li><li>b. 旧的consumer挂了</li><li>c. coordinator挂了，集群选举出新的coordinator</li><li>d. topic的partition新加</li><li>e. consumer调用unsubscrible()，取消topic的订阅</li></ul></div><blockquote><p>rebalance发生时，Group下所有consumer实例都会协调在一起共同参与， kafka能够保证尽量达到最公平的分配，但是Rebalance过程对consumer group会造成比较严重的影响， 在Rebalance的过程中consumer group下的所有消费者实例都会停止工作，等待rebalance过程完成</p></blockquote><h2 id="_42-rebalance影响" tabindex="-1">42 rebalance影响 <a class="header-anchor" href="#_42-rebalance影响" aria-hidden="true">#</a></h2><ol><li>数据重复消费：消费过的数据由于提交offset任务也会失败，在partition被分配给其他消费者的时候，会造成重复消费，数据重复且增加集群压力</li><li>rebalance扩散到整个consumerGroup的所有消费者，因为一个消费者的退出，导致整个group进行rebalance，并在一个比较慢的时间内达到稳定状态，影响面较大</li><li>频繁的rebalance反而降低了消息的消费速度，大部分时间都在重复消费和rebalance</li><li>数据不能及时消费，会累积lag，在kafka的ttl之后会丢弃数据上面的影响对于我们系统来说，是致命的</li></ol><h2 id="_43-如何解决rebalance问题" tabindex="-1">43 如何解决rebalance问题 <a class="header-anchor" href="#_43-如何解决rebalance问题" aria-hidden="true">#</a></h2><div class="tip custom-block"><p class="custom-block-title">发生时机</p><ul><li>a. 组成员数量发生变化</li><li>b. 订阅主题数量发生变化（可人为避免）</li><li>c. 订阅主题的分区数发生变化（可人为避免）</li></ul></div><ol><li>消费者成员正常的添加和停掉无法避免，但是在某些情况下，consumer实例被coordinator错误地认为已停止，从而被剔出group，导致rebalance</li><li>当consumer group完成rebalance之后，每个consumer实例都会定期地向coordinator发送心跳请求，表明它还存活着，如果某个consumer实例不能及时地发送这些心跳请求，coordinator就会认为该consumer已经死了，从被移除，再开启新一轮rebalance，这个时间可以通过consumer端的参数session.timeout.ms进行配置，默认值是10秒</li><li>consumer提供了控制发送心跳请求频率的参数，<a href="http://xn--heartbeat-uv5qk39f.interval.ms" target="_blank" rel="noopener noreferrer">就是heartbeat.interval.ms</a>。这个值设置的越小，consumer实例发送心跳请求的频率就越高，频繁地发送心跳请求会额外消耗带宽资源，好处是能够更加快速地知晓当前是否开启rebalance，coordinator通知各个consumer实例开启rebalance的方法，就是将rebalance_needed标志封装进心跳请求的响应体中。</li><li>max.poll.interval.ms参数，它限定了consumer端应用程序两次调用poll方法的最大时间间隔，它的默认值是5分钟，表示你的consumer程序如果在5分钟之内无法消费完poll方法返回的消息，那么consumer会主动发起”离开组“的请求，coordinator也会开启新一轮的rebalance</li><li>设置session.timeout.ms=6s，设置heartbeat.interval.ms=2s，要保证consumer实例在被判定为”dead“之前，能够发送至少3轮的心跳请求，<a href="http://xn--session-zx2l.timeout.ms" target="_blank" rel="noopener noreferrer">即session.timeout.ms</a>&gt;=3*<a href="http://heartbeat.interval.ms" target="_blank" rel="noopener noreferrer">heartbeat.interval.ms</a></li><li>rebalance是consumer消费时间过长导致的，max.poll.interval.ms参数，如果要避免非预期的rebalance，你最好将该参数值设置得大一些。</li></ol><h2 id="_44-kafka为何快" tabindex="-1">44 kafka为何快 <a class="header-anchor" href="#_44-kafka为何快" aria-hidden="true">#</a></h2><ol><li>实现了零拷贝原理，快速移动数据，避免内核之间切换</li><li>将数据记录分批发送，从生产者到文件系统（主题日志）到消费者，可端到端的查看这些批次的数据。</li><li>批处理能够进行更有效的数据压缩并减少I/O延迟，kafka采取顺序写磁盘的方式，避免随机磁盘寻址的浪费</li><li>顺序读写、零拷贝、消息压缩、分批发送</li></ol><h2 id="_45-kafka" tabindex="-1">45 kafka <a class="header-anchor" href="#_45-kafka" aria-hidden="true">#</a></h2><ul><li>分布式流处理平台，用于实时构建流处理应用，核心：消息总线</li><li>轻松推送记录</li><li>存储大量记录，不会出现任何存储问题</li><li>在记录进入时对其进行处理</li></ul><h2 id="_46-kafka-vs-zookeeper" tabindex="-1">46 kafka vs zookeeper <a class="header-anchor" href="#_46-kafka-vs-zookeeper" aria-hidden="true">#</a></h2><ul><li>zk是一个分布式的协调组件，早期kafka用zk做meta信息存储，consumer的消费状态，</li><li>group的管理以及offset的值，考虑到zk本身对架构存在单点问题进行了弱化。</li><li>broker依赖zk，用来选举controller和检测broker是否存活</li></ul><h2 id="_47-isr、ar、osr" tabindex="-1">47 ISR、AR、OSR <a class="header-anchor" href="#_47-isr、ar、osr" aria-hidden="true">#</a></h2><ul><li>isr。In-Sync Replicas 副本同步队列</li><li>osr。Outof-Sync Replicas</li><li>ar。Assigned Replicas所有副本</li></ul><blockquote><p>AR = ISR + OSR</p></blockquote><h2 id="_48-follower如何与leader同步数据" tabindex="-1">48 follower如何与leader同步数据 <a class="header-anchor" href="#_48-follower如何与leader同步数据" aria-hidden="true">#</a></h2><ol><li>kafka的复制机制既不是完全的同步复制，也不是单纯的异步复制</li><li>完全同步复制要求all alive follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响吞吐率</li><li>异步复制方式，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下，如果leader挂掉，会丢失数据，kafka使用isr的方式很好均衡了确保数据不丢失以及吞吐率。</li><li>follower可批量从leader复制数据，而且leader充分利用磁盘顺序读以及sendfile（zero copy）机制，内部批量写磁盘。</li></ol><h2 id="_49-kafka-可以脱离-zookeeper-单独使用吗？" tabindex="-1">49 kafka 可以脱离 zookeeper 单独使用吗？ <a class="header-anchor" href="#_49-kafka-可以脱离-zookeeper-单独使用吗？" aria-hidden="true">#</a></h2><ol><li>kafka 不能脱离 zookeeper 单独使用，</li><li>因为 kafka 使用 zookeeper 管理和协调 kafka 的节点服务器。</li></ol><h2 id="_50-kafka-有几种数据保留的策略？" tabindex="-1">50 kafka 有几种数据保留的策略？ <a class="header-anchor" href="#_50-kafka-有几种数据保留的策略？" aria-hidden="true">#</a></h2><p>kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。</p><h2 id="_51-kafka-同时设置了-7-天和-10g-清除数据，到第五天的时候消息达到了-10g，这个时候-kafka-将如何处理？" tabindex="-1">51 kafka 同时设置了 7 天和 10G 清除数据，到第五天的时候消息达到了 10G，这个时候 kafka 将如何处理？ <a class="header-anchor" href="#_51-kafka-同时设置了-7-天和-10g-清除数据，到第五天的时候消息达到了-10g，这个时候-kafka-将如何处理？" aria-hidden="true">#</a></h2><p>这个时候kafka 会执行数据清除工作，时间和大小不论那个满足条件，都会清空数据。</p><h2 id="_52-什么情况会导致-kafka-运行变慢？" tabindex="-1">52 什么情况会导致 kafka 运行变慢？ <a class="header-anchor" href="#_52-什么情况会导致-kafka-运行变慢？" aria-hidden="true">#</a></h2><ul><li>cpu 性能瓶颈</li><li>磁盘读写瓶颈</li><li>网络瓶颈</li></ul><h2 id="_53-使用-kafka-集群需要注意什么？" tabindex="-1">53 使用 kafka 集群需要注意什么？ <a class="header-anchor" href="#_53-使用-kafka-集群需要注意什么？" aria-hidden="true">#</a></h2><ul><li>集群的数量不是越多越好，最好不要超过7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。</li><li>集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。</li></ul></div></div></main><footer class="VPDocFooter" data-v-3886f8ec data-v-4fc1a8f4><div class="edit-info" data-v-4fc1a8f4><div class="edit-link" data-v-4fc1a8f4><a class="VPLink link edit-link-button" href="https://github.com/space2030?tab=repositories" target="_blank" rel="noopener noreferrer" data-v-4fc1a8f4 data-v-8dd034e6><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" data-v-4fc1a8f4><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> 在 github 上编辑此页<!--]--><!----></a></div><div class="last-updated" data-v-4fc1a8f4><p class="VPLastUpdated" data-v-4fc1a8f4 data-v-537b088a>最后更新: <time datatime="2023-10-19T07:32:22.000Z" data-v-537b088a></time></p></div></div><!----></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter" data-v-581d5782 data-v-3d0cd5b8><div class="container" data-v-3d0cd5b8><p class="message" data-v-3d0cd5b8>Released under the MIT License.</p><p class="copyright" data-v-3d0cd5b8>Copyright © 2023-present Evan You</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"index.md\":\"f37252e3\",\"src_case_example_aqs抽象队列同步器.md\":\"24756237\",\"src_case_example_arraylist扩容机制解析.md\":\"a4b8bed3\",\"src_case_example_arrays类sort()方法使用的排序算法.md\":\"ccfbb6ab\",\"src_case_example_concurrenthashmap为什么放弃了分段锁.md\":\"0a4ffee0\",\"src_case_example_es与mysql数据不一致.md\":\"d871661c\",\"src_case_example_redis与mysql数据不一致.md\":\"26418c82\",\"src_case_example_tomcat性能优化.md\":\"dfbb266f\",\"src_case_example_中间件设计.md\":\"468e8da7\",\"src_case_example_代码片段.md\":\"925caa6b\",\"src_case_example_分布式事务解决方案.md\":\"2f070cfb\",\"src_case_example_分布式唯一id.md\":\"23eadd1f\",\"src_case_example_分布式锁-基于数据库的实现.md\":\"4d8b29d2\",\"src_case_example_分库分表.md\":\"c52281c2\",\"src_case_example_如何处理千万级别mysql数据库锁表问题.md\":\"b4c0af50\",\"src_case_example_如何快速从千万级大表删除数据.md\":\"91fe5800\",\"src_case_example_批量处理数据.md\":\"78b0d9bb\",\"src_case_example_接口性能优化.md\":\"9d1792f7\",\"src_case_example_架构设计.md\":\"d307ccb7\",\"src_case_example_百万级别数据导入导出如何优化.md\":\"98a549ab\",\"src_case_example_百万级数据深度分页如何优化.md\":\"32c9674d\",\"src_case_example_秒杀.md\":\"fcad5d18\",\"src_case_example_系统设计规范.md\":\"15c311eb\",\"src_case_example_线上环境踩坑之并行流丢失数据.md\":\"1c3be8f9\",\"src_case_example_线程池.md\":\"e4225766\",\"src_case_example_综合面.md\":\"f493e2fa\",\"src_case_example_网络.md\":\"2753f5be\",\"src_case_example_设计接口.md\":\"38f526c0\",\"src_case_example_设计模式.md\":\"47a4706e\",\"src_case_example_重构.md\":\"f8b1bb82\",\"src_case_index.md\":\"e7293aa9\",\"src_case_norm_javascript规范.md\":\"9fb24129\",\"src_case_norm_java规范.md\":\"538dd69a\",\"src_case_norm_markdown规范.md\":\"2b32c5f2\",\"src_case_norm_vue规范.md\":\"898eb012\",\"src_case_norm_前后端规约.md\":\"e89a40a3\",\"src_case_norm_接口对接规范.md\":\"6d91f32f\",\"src_case_norm_日志规范.md\":\"f59ee845\",\"src_case_redis操作.md\":\"2f51e4c7\",\"src_deploy_index.md\":\"6cb4a725\",\"src_deploy_mongodb部署.md\":\"8a227b4a\",\"src_deploy_mysql部署.md\":\"11af5f81\",\"src_deploy_node部署.md\":\"fdf9e10a\",\"src_deploy_oracle部署.md\":\"f730433a\",\"src_deploy_redis部署.md\":\"ad57b569\",\"src_git_index.md\":\"1f809b9a\",\"src_index_index.md\":\"33da6e30\",\"src_kit_blog.md\":\"1c11ac7e\",\"src_kit_index.md\":\"04dd6794\",\"src_kit_nginx.md\":\"5c165844\",\"src_kit_tool.md\":\"d4ebdde9\",\"src_view_index.md\":\"dc64bfa6\",\"src_view_java_java-01-se.md\":\"d50e6d5e\",\"src_view_java_java-02-ee.md\":\"06cece6f\",\"src_view_java_java-03-tomcat.md\":\"4e071e95\",\"src_view_java_java-04-spring.md\":\"294e3736\",\"src_view_java_java-05-mybatis.md\":\"f08a45bf\",\"src_view_java_java-06-spring-boot.md\":\"0aff5c53\",\"src_view_java_java-07-maven.md\":\"cd8805f9\",\"src_view_java_java-08-spring-cloud.md\":\"9b8482f6\",\"src_view_java_java-09-mysql.md\":\"00f74996\",\"src_view_java_java-10-redis.md\":\"07f078ba\",\"src_view_java_java-11-oracle.md\":\"333de976\",\"src_view_java_java-12-gateway.md\":\"d8b6a793\",\"src_view_java_java-13-elasticsearch.md\":\"b01a920e\",\"src_view_java_java-14-mongodb.md\":\"a29b919f\",\"src_view_java_java-15-rocketmq.md\":\"2983da5e\",\"src_view_java_java-16-activemq.md\":\"d2aa5ffd\",\"src_view_java_java-17-rabbitmq.md\":\"ed854218\",\"src_view_java_java-18-zookeeper.md\":\"2bb8ca84\",\"src_view_java_java-19-kafka.md\":\"ef7bf4c5\",\"src_view_web_web-01-html.md\":\"f76a68db\",\"src_view_web_web-02-javascript.md\":\"560f2ce1\",\"src_view_web_web-03-vue.md\":\"e6cb6cc4\",\"src_web_index.md\":\"4759f761\",\"src_web_vitepress_vitepress快速开始.md\":\"86859a47\",\"src_web_vitepress_vitepress语法规则.md\":\"e4ba6974\",\"src_web_vitepress_vitepress项目发布.md\":\"246085db\"}")</script>
    <script type="module" async src="/vitepress-deploy/assets/app.2a154df8.js"></script>
    
  </body>
</html>