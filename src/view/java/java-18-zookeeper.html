<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>zookeeper 原理</title>
    <meta name="description" content="VitePress">
    <link rel="stylesheet" href="/vitepress-deploy/assets/style.c6a8f29c.css">
    <link rel="modulepreload" href="/vitepress-deploy/assets/app.2a154df8.js">
    <link rel="modulepreload" href="/vitepress-deploy/assets/src_view_java_java-18-zookeeper.md.2bb8ca84.lean.js">
    
    <link rel="icon" href="https://cn.vitejs.dev/logo-with-shadow.png">
  <script>(()=>{const e=localStorage.getItem("vitepress-theme-appearance"),a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-581d5782><!--[--><!--]--><!--[--><span tabindex="-1" data-v-2c02b834></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-2c02b834> Skip to content </a><!--]--><!----><header class="VPNav no-sidebar" data-v-581d5782 data-v-119e663c><div class="VPNavBar" data-v-119e663c data-v-1f7b674d><div class="container" data-v-1f7b674d><div class="VPNavBarTitle" data-v-1f7b674d data-v-ed531ba2><a class="title" href="/vitepress-deploy/" data-v-ed531ba2><!--[--><img class="VPImage logo" src="https://cn.vitejs.dev/logo-with-shadow.png" data-v-81172f9c><!--]--><!--[-->首页<!--]--></a></div><div class="content" data-v-1f7b674d><!----><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-1f7b674d data-v-192c109a><span id="main-nav-aria-label" class="visually-hidden" data-v-192c109a>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/view/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->问答<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/web/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->前端<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/deploy/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->部署<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/kit/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->工具<!--]--><!----></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-deploy/src/case/index.html" data-v-192c109a data-v-4d31877c data-v-8dd034e6><!--[-->案例<!--]--><!----></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-1f7b674d data-v-5cf7609e><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-5cf7609e data-v-766c3cb1 data-v-d6dfd774><span class="check" data-v-d6dfd774><span class="icon" data-v-d6dfd774><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-766c3cb1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-766c3cb1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-1f7b674d data-v-a767cbbe data-v-e03f590e><!--[--><a class="VPSocialLink" href="https://github.com/space2030?tab=repositories" title="github" target="_blank" rel="noopener noreferrer" data-v-e03f590e data-v-3dd9970c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-3dd9970c><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden" data-v-3dd9970c>github</span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-1f7b674d data-v-6a32f7d6 data-v-44cec2e6><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-44cec2e6><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-44cec2e6><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-44cec2e6><div class="VPMenu" data-v-44cec2e6 data-v-ddb22576><!----><!--[--><!--[--><!----><div class="group" data-v-6a32f7d6><div class="item appearance" data-v-6a32f7d6><p class="label" data-v-6a32f7d6>Appearance</p><div class="appearance-action" data-v-6a32f7d6><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" aria-label="toggle dark mode" data-v-6a32f7d6 data-v-766c3cb1 data-v-d6dfd774><span class="check" data-v-d6dfd774><span class="icon" data-v-d6dfd774><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-766c3cb1><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-766c3cb1><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><div class="group" data-v-6a32f7d6><div class="item social-links" data-v-6a32f7d6><div class="VPSocialLinks social-links-list" data-v-6a32f7d6 data-v-e03f590e><!--[--><a class="VPSocialLink" href="https://github.com/space2030?tab=repositories" title="github" target="_blank" rel="noopener noreferrer" data-v-e03f590e data-v-3dd9970c><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-3dd9970c><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg><span class="visually-hidden" data-v-3dd9970c>github</span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-1f7b674d data-v-3524c702><span class="container" data-v-3524c702><span class="top" data-v-3524c702></span><span class="middle" data-v-3524c702></span><span class="bottom" data-v-3524c702></span></span></button></div></div></div><!----></header><!----><!----><div class="VPContent" id="VPContent" data-v-581d5782 data-v-804f35da><div class="VPDoc" data-v-804f35da data-v-3886f8ec><div class="container" data-v-3886f8ec><div class="aside" data-v-3886f8ec><div class="aside-curtain" data-v-3886f8ec></div><div class="aside-container" data-v-3886f8ec><div class="aside-content" data-v-3886f8ec><div class="VPDocAside" data-v-3886f8ec data-v-a4f49d12><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline has-outline" data-v-a4f49d12 data-v-2d325df8><div class="content" data-v-2d325df8><div class="outline-marker" data-v-2d325df8></div><div class="outline-title" data-v-2d325df8>目录</div><nav aria-labelledby="doc-outline-aria-label" data-v-2d325df8><span class="visually-hidden" id="doc-outline-aria-label" data-v-2d325df8> Table of Contents for current page </span><ul class="root" data-v-2d325df8><!--[--><li style="" data-v-2d325df8><a class="outline-link" href="#_01-定义" data-v-2d325df8>01 定义</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_02-文件系统" data-v-2d325df8>02 文件系统</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_03-zab协议" data-v-2d325df8>03 ZAB协议</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_04-znode" data-v-2d325df8>04 ZNode</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_05-watcher-机制" data-v-2d325df8>05 Watcher 机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_06-队列管理" data-v-2d325df8>06 队列管理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_07-zookeeper-定义" data-v-2d325df8>07 zookeeper 定义</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_08-zk提供服务" data-v-2d325df8>08 zk提供服务</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_09-zk文件系统" data-v-2d325df8>09 zk文件系统</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_10-四种类型的znode" data-v-2d325df8>10 四种类型的znode</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_11-zk通知机制" data-v-2d325df8>11 zk通知机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_12-zk功能" data-v-2d325df8>12 zk功能</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_13-zk命名服务" data-v-2d325df8>13 zk命名服务</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_14-zk配置管理" data-v-2d325df8>14 zk配置管理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_15-zk集群管理" data-v-2d325df8>15 zk集群管理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_16-zk分布式锁" data-v-2d325df8>16 zk分布式锁</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_17-获取分布式锁的流程" data-v-2d325df8>17 获取分布式锁的流程</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_18-zk队列管理" data-v-2d325df8>18 zk队列管理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_19-zookeeper的数据模型" data-v-2d325df8>19 zookeeper的数据模型</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_20-如何识别请求的先后顺序" data-v-2d325df8>20 如何识别请求的先后顺序</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_21-znode的类型" data-v-2d325df8>21 ZNode的类型</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_21-zookeeper定义了几种权限" data-v-2d325df8>21 zookeeper定义了几种权限</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_22-zab" data-v-2d325df8>22 ZAB</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_23-什么情况会导致zab进入崩溃恢复模式并选取出新的leader" data-v-2d325df8>23 什么情况会导致ZAB进入崩溃恢复模式并选取出新的leader</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_24-watch监听器" data-v-2d325df8>24 watch监听器</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_25-客户端如何获取配置信息" data-v-2d325df8>25 客户端如何获取配置信息</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_26-zk数据复制" data-v-2d325df8>26 zk数据复制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_27-zk工作原理" data-v-2d325df8>27 zk工作原理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_28-zk如何保证事务的顺序一致性" data-v-2d325df8>28 zk如何保证事务的顺序一致性</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_29-zk下server工作状态" data-v-2d325df8>29 zk下server工作状态</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_30-zk是选取leader" data-v-2d325df8>30 zk是选取leader</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_31-zk选主流程" data-v-2d325df8>31 zk选主流程</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_32-zk选主流程" data-v-2d325df8>32 zk选主流程</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_33-zk同步流程" data-v-2d325df8>33 zk同步流程</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_34-分布式通知和协调" data-v-2d325df8>34 分布式通知和协调</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_35-机器中leader" data-v-2d325df8>35 机器中leader</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_36-zk节点宕机如何处理" data-v-2d325df8>36 zk节点宕机如何处理</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_37-zk-watch机制" data-v-2d325df8>37 zk watch机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_38-zk对节点的watch监听通知是永久的吗" data-v-2d325df8>38 zk对节点的watch监听通知是永久的吗</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_39-zab和paxos算法" data-v-2d325df8>39 zab和paxos算法</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_40-nginx如何处理http请求" data-v-2d325df8>40 Nginx如何处理HTTP请求</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_41-nginx高并发" data-v-2d325df8>41 Nginx高并发</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_42-内存屏障" data-v-2d325df8>42 内存屏障</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_43-zookeeper-功能" data-v-2d325df8>43 zookeeper 功能</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_44-zookeeper-有几种部署模式？" data-v-2d325df8>44 zookeeper 有几种部署模式？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_45-zookeeper-怎么保证主从节点的状态同步？" data-v-2d325df8>45 zookeeper 怎么保证主从节点的状态同步？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_46-集群中为什么要有主节点？" data-v-2d325df8>46 集群中为什么要有主节点？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_47-集群中有-3-台服务器，其中一个节点宕机，这个时候-zookeeper-还可以使用吗？" data-v-2d325df8>47 集群中有 3 台服务器，其中一个节点宕机，这个时候 zookeeper 还可以使用吗？</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_48-zookeeper-通知机制" data-v-2d325df8>48 zookeeper 通知机制</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_49-zk-对节点的-watch-监听通知是永久的吗" data-v-2d325df8>49 zk 对节点的 watch 监听通知是永久的吗</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_50-zab-和-paxos-算法" data-v-2d325df8>50 zab 和 paxos 算法</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_51-nginx-如何处理-http-请求" data-v-2d325df8>51 nginx 如何处理 http 请求</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_52-nginx-高并发" data-v-2d325df8>52 nginx 高并发</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_53-内存屏障" data-v-2d325df8>53 内存屏障</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_54-柔性事务" data-v-2d325df8>54 柔性事务</a><!----></li><li style="" data-v-2d325df8><a class="outline-link" href="#_55-zookeeper-实现分布式锁" data-v-2d325df8>55 zookeeper 实现分布式锁</a><!----></li><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-a4f49d12></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-3886f8ec><div class="content-container" data-v-3886f8ec><!--[--><!--]--><main class="main" data-v-3886f8ec><div style="position:relative;" class="vp-doc _vitepress-deploy_src_view_java_java-18-zookeeper" data-v-3886f8ec><div><h1 id="zookeeper-原理" tabindex="-1">zookeeper 原理 <a class="header-anchor" href="#zookeeper-原理" aria-hidden="true">#</a></h1><h1 id="zk" tabindex="-1">ZK <a class="header-anchor" href="#zk" aria-hidden="true">#</a></h1><h3 id="_1-zk" tabindex="-1">1. ZK <a class="header-anchor" href="#_1-zk" aria-hidden="true">#</a></h3><ol><li>维护、协调、管理、监控</li><li>特点 <ol><li>最终一致性</li><li>可靠性，服务器保存了消息，那么它就一直都存在</li><li>实时性，zk 不能保证两个客户端同时得到刚更新的数据</li><li>独立性，不同客户端之间互不影响</li><li>原子性，更新要不成功要不失败，没有第三个状态</li></ol></li></ol><h3 id="_2、应用场景" tabindex="-1">2、应用场景 <a class="header-anchor" href="#_2、应用场景" aria-hidden="true">#</a></h3><h4 id="_2-1、数据发布与订阅" tabindex="-1">2.1、数据发布与订阅 <a class="header-anchor" href="#_2-1、数据发布与订阅" aria-hidden="true">#</a></h4><ol><li>数据发布与订阅，就是将数据发布到 zk 节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，地址列表等</li><li>数据发布订阅的一个常见的场景是配置中心，发布者把数据发布到 zk 的一个或一系列的节点上，供订阅者进行数据订阅，达到动态获取数据的目的。</li><li>配置信息一般有几个特点 <ol><li>数据量小的KV</li><li>数据内容在运行时发生动态变化</li><li>集群机器共享，配置一致</li></ol></li><li>zk 采用的推拉结合的方式 <ol><li>推：服务端会推给注册了监控节点的客户端 watcher 事件通知</li><li>拉：客户端获得通知后，然后主动到服务端拉取最新的数据</li></ol></li></ol><h4 id="_2-2、命名服务" tabindex="-1">2.2、命名服务 <a class="header-anchor" href="#_2-2、命名服务" aria-hidden="true">#</a></h4><ol><li>作为分布式命名服务，命名服务是指通过指定的名字来获取资源或者服务的地址，利用 zk 创建一个全局的路径，这个路径就可以作为一个名字，指向集群中的集群，提供的服务地址或者一个远程的对象等。</li><li>在分布式环境下，经常需要对应用/服务进行统一命名，便于识别不同服务。</li><li>类似于域名与IP 之间对应关系</li><li>通过名称来获取资源或服务的地址，提供者等信息</li><li>按照层次结构组织服务/应用名称，可将服务名称以及地址信息写到 zk 上，客户端通过 zk 获取可用服务列表类</li></ol><h4 id="_2-3、配置管理" tabindex="-1">2.3、配置管理 <a class="header-anchor" href="#_2-3、配置管理" aria-hidden="true">#</a></h4><ol><li>程序分布式的部署在不同的机器上，将程序的配置信息放在 zk 的 znode 下，当有配置发生改变时，也就是 znode 发生变化时，可以通过改变 zk 中某个目录节点的内容，利用 watch 通知给各个客户端，从而更改配置。</li><li>zk 配置管理结构 <ol><li>分布式环境下，配置文件管理和同步是一个常见问题</li><li>一个集群中，所有节点的配置信息是一致的，比如 Hadoop 集群</li><li>对配置文件修改后，希望能够快速同步到各个节点上。</li></ol></li><li>配置管理可交由 zk 实现 <ol><li>可将配置信息写入 zk 上的一个 znode</li><li>各个节点监听这个 znode</li><li>一旦 znode 中的数据被修改，zk 将通知各个节点</li></ol></li></ol><h4 id="_2-4、集群管理" tabindex="-1">2.4、集群管理 <a class="header-anchor" href="#_2-4、集群管理" aria-hidden="true">#</a></h4><ol><li><p>所谓集群管理就是：是否有机器退出和加入，选举 master</p></li><li><p>集群管理主要指集群监控和集群控制两个方面，前者侧重于集群运行时的状态和收集，后者则是对集群进行操作与控制，开发和运维中，面对集群，经常有如下需求。</p><ol><li>希望知道集群中究竟有多少机器在工作</li><li>对集群中的每台机器的运行时状态进行数据收集</li><li>对集群中机器进行上下线的操作</li></ol></li><li><p>集群结构</p><ol><li>分布式环境中，实时掌握每个节点的状态是必要的，可根据节点实时状态做出一些调整</li><li>可交由 zk 实现 <ol><li>可将节点信息写入 zk 上的一个 znode</li><li>监听这个 znode 可获取它的实时状态变化</li></ol></li><li>典型应用 <ol><li>Hbase中 Master 状态监控与选举</li></ol></li></ol></li></ol><h4 id="_2-5、分布式通知与协调" tabindex="-1">2.5、分布式通知与协调 <a class="header-anchor" href="#_2-5、分布式通知与协调" aria-hidden="true">#</a></h4><ol><li>分布式环境中，经常存在一个服务需要知道它所管理的子服务的状态</li><li>心跳检测机制可通过 zk 来实现</li><li>信息推送可由 zk 来实现，zk 相当于一个发布/订阅系统</li></ol><h4 id="_2-6、分布式锁" tabindex="-1">2.6、分布式锁 <a class="header-anchor" href="#_2-6、分布式锁" aria-hidden="true">#</a></h4><ol><li>处于不同节点上不同的服务，它们可能需要顺序的访问一些资源，这里需要一把分布式锁</li><li>分布式锁具有以下特性：写锁、读锁、时序锁 <ol><li>写锁：在 zk 上创建的一个临时的无编号的节点。由于是无序编号，在创建时不会自动编号，导致只能客户端有一个客户端得到锁，然后进行写入。</li><li>读锁：在 zk 上创建一个临时的有编号的节点，这样即使下次有客户端加入是同时创建相同的节点时，它也会自动编号，也可以获得锁对象，然后对其进行读取，</li><li>时序锁：在 zk 上创建的一个临时的有编号的节点根据变化的大小控制锁。</li></ol></li></ol><h4 id="_2-7、分布式队列" tabindex="-1">2.7、分布式队列 <a class="header-anchor" href="#_2-7、分布式队列" aria-hidden="true">#</a></h4><ol><li>当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列 <ol><li>一个 job 由多个 task 组成，只有所有任务完成后，job 才运行完成</li><li>可为 job 创建一个 job 目录，然后在该目录下，为每个完成的 task 创建一个临时的 znode ，一旦临时节点数目达到 task 总数，则表明 job 运行完成。</li></ol></li><li>队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。</li></ol><h3 id="_3、zk-工作原理" tabindex="-1">3、zk 工作原理 <a class="header-anchor" href="#_3、zk-工作原理" aria-hidden="true">#</a></h3><ol><li><p>zk 机制保证了各个 Server 之间的同步，实现这个机制的协议叫做 zab 协议</p></li><li><p>zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）</p><ol><li>zab 协议的全称是 zookeeper atomic broadcast (zk 原子广播)，zk 是通过 zab 协议来保证分布式事务的最终一致性，zab 协议要求每个 leader 都要经历三个阶段：发现，同步，广播。</li><li>当服务启动或者在领导者崩溃后，zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了</li><li>状态同步保证了 leader 和 server 具有相同的系统状态。</li></ol></li><li><p>为了保证事务的顺序一致性，zk 采用了递增的事务 id 号（zxid）来标识事务，所有的提议（proposal）都在被提出的时候加上了 zxid。实现在 zxid 是一个 64 位的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期，低 32 位用于递增计数</p><blockquote><p>epoch：可以理解为皇帝年号，当新的皇帝 leader 产生后，将有一个新的 epoch 年号</p></blockquote><p>每个 server 在工作过程中有三种状态：</p><ul><li>LOOKING：当前 Server 不知道 Leader 是谁，正在搜寻</li><li>LEADING：当前 Server 即选举出来的 Leader</li><li>FOLLOWING：leader 已经选举出来，当前 Server 与之同步。</li></ul></li></ol><h3 id="_4、zk-通知机制" tabindex="-1">4、zk 通知机制 <a class="header-anchor" href="#_4、zk-通知机制" aria-hidden="true">#</a></h3><ol><li><p>zk 允许客户端向服务端的某个 znode 注册一个 watcher 监听，当服务端的一些指定事件触发了这个 watcher ，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 watcher 通知状态和事件类型做出业务上的改变。</p><ol><li><p>大致分为三个步骤</p><ol><li>客户端注册 watcher <ol><li>调用 getData、getChildren、exist 三个 API，传入 Watcher 对象</li><li>标记请求 request，封装 watcher 到 watchRegistration</li><li>封装成 Packet 对象，发服务端发送 request</li><li>收到服务端响应后，将 watcher 注册到 zkwatcherManager 中进行管理</li><li>请求返回，完成注册</li></ol></li><li>服务端处理 watcher <ol><li>服务端接收 watcher 并存储</li><li>watcher 触发</li><li>调用 process 方法来触发 watcher</li></ol></li><li>客户端回调 watcher <ol><li>客户端 sendThread 线程接收事件通知，交由 eventThread 线程回调 watcher</li><li>客户端的watcher 机制同样是一次性的，一旦被触发后，该watcher 就失效了</li></ol></li></ol><blockquote><p>client 端对某个 znode 建立一个watcher 事件，当该 znode 发生变化时，这些 client 会收到 zk 通知，然后 client 可以根据 znode 变化来做出业务上的改变。</p></blockquote></li></ol></li></ol><h3 id="_5、zk-的-watch-监听通知是永久的吗" tabindex="-1">5、zk 的 watch 监听通知是永久的吗 <a class="header-anchor" href="#_5、zk-的-watch-监听通知是永久的吗" aria-hidden="true">#</a></h3><ol><li>不是，一次性的</li><li>无论是服务端还是客户端，一旦一个 watcher 被触发，zk 都会将其从相应的存储中移除</li><li>这样的设计有效的减轻了服务端的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知，无论对于网络还是服务端的压力都非常大。</li></ol><h3 id="_6、zk-角色" tabindex="-1">6、zk 角色 <a class="header-anchor" href="#_6、zk-角色" aria-hidden="true">#</a></h3><ol><li>leader 事务请求的唯一调度和处理者，保证集群事务处理的顺序性，集群内部各服务的调度者</li><li>follower <ol><li>处理客户端的非事务请求，转发事务请求给 leader 服务器</li><li>参与事务请求 proposal 的投票</li><li>参与 leader 选举投票</li></ol></li><li>observer <ol><li>处理客户端的非事务请求，转发事务请求给 leader 服务器</li><li>不参与任何形式的投票</li><li>observer 不属于法定人数，即不参加选举也不响应提议，也不参与写操作，过半写成功策略</li><li>observer 不需要将事务持久化到磁盘，一旦 observer 被重启，需要从 leader 重新同步整个名字空间。</li></ol></li></ol><h3 id="_7、zk-集群中-server-工作状态" tabindex="-1">7、zk 集群中 server 工作状态 <a class="header-anchor" href="#_7、zk-集群中-server-工作状态" aria-hidden="true">#</a></h3><ul><li>LOOKING <ul><li>寻找 Leader 状态；当服务器处于该状态时，它会认为当前集群中没有 Leader，因此需要进入 Leader 选举状态。</li></ul></li><li>FOLLOWING <ul><li>跟随者状态；表明当前服务器角色是 Follower</li></ul></li><li>LEADING <ul><li>领导者状态；表明当前服务器角色是 Leader</li></ul></li><li>OBSERVING <ul><li>观察者状态；表明当前服务器角色是 Observer</li></ul></li></ul><h3 id="_8、zk-集群中是怎样选举leader" tabindex="-1">8、zk 集群中是怎样选举leader <a class="header-anchor" href="#_8、zk-集群中是怎样选举leader" aria-hidden="true">#</a></h3><ol><li>leader 崩溃了，或者失去了大多数的 follower ，这时候 zk 就进入恢复模式，恢复模式需要重新选举出一个新的 leader ，让所有的 server 都恢复到一个状态 looking</li><li>basic paxos 实现和基于 fast paxos 实现，默认 fast paxos</li></ol><h3 id="_9、zk-事务顺序一致性" tabindex="-1">9、zk 事务顺序一致性 <a class="header-anchor" href="#_9、zk-事务顺序一致性" aria-hidden="true">#</a></h3><ol><li>zk 采用了递增的事务 id 来识别，所有的 proposal （提议）都在被提出的时候加上了 zxid</li><li>zxid 实际上是一个 64 位数字</li><li>高32 位是 epoch 用来标识 leader 是否发生了改变，如果有新的 leader 产生出来，epoch 会自增，低 32 位用来递增计数。当新产生的 proposal 的时候，会依据数据的两阶段过程，首先会向其他的 server 发出事务的执行请求，如果超过半数的机器都能执行并且能够成功，那么就会开始执行。</li></ol><h3 id="_10、zk-集群中服务器通信" tabindex="-1">10、zk 集群中服务器通信 <a class="header-anchor" href="#_10、zk-集群中服务器通信" aria-hidden="true">#</a></h3><ol><li>leader 服务器会和每一个 follower / observer 服务器都建立 tcp 连接，同时为每个 follower / observer 都创建一个叫做 learnerHandler 的实体。</li><li>learnerHandler 主要负责 leader 和 follower / observer 之间的网络通讯，包括数据同步，请求转发和 proposal 提议的投票</li><li>leader 服务器保存了所有 follower / observer 的 learnerHander</li></ol><h3 id="_11、zk-分布式锁" tabindex="-1">11、zk 分布式锁 <a class="header-anchor" href="#_11、zk-分布式锁" aria-hidden="true">#</a></h3><ol><li>如果有客户端1、客户端2 等 N 个客户端争抢一个 zk 分布式锁，大致如下 <ol><li>大家都是上来直接创建一个锁节点下的一个接一个的临时有序节点</li><li>如果自己不是第一节点，就对自己上一个节点加监听器</li><li>只要上一个节点释放锁，自己就排到前面去了，相当于是一个排队机制</li></ol></li></ol><p>而且用临时顺序节点的另外一个用意就是，如果某个客户端创建临时顺序节点之后，不小心自己宕机了也没关系，zk 感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁，或者是自动取消自己的排队。</p><p>本地锁，可以用 JDK 实现，但是分布式锁就必须要用到分布式的组件</p><ul><li>死锁问题：锁不能因为意外就变成死锁，所以要用 ZK 的临时节点，客户端连接失效了，锁就自动释放了</li><li>锁等待问题：锁有排队的需求，所以要 ZK 的顺序节点。</li><li>锁管理问题：释放了锁，需要通知其他使用者，所以需要用到监听</li><li>监听的羊群效应：比如有 1000 个锁竞争者，锁释放了，1000 个竞争者就得到了通知，然后判断，最终序号最小的那个拿个锁，其它 999 个竞争者重新注册监听，这就是羊群效应，出点事，就会惊动整个羊群，使用链式处理，每个竞争者只监听自己前面的那个节点，比如：2 号释放了锁，那么只有 3 号得到了通知。</li></ul><h2 id="_01-定义" tabindex="-1">01 定义 <a class="header-anchor" href="#_01-定义" aria-hidden="true">#</a></h2><p>一个分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作。</p><h2 id="_02-文件系统" tabindex="-1">02 文件系统 <a class="header-anchor" href="#_02-文件系统" aria-hidden="true">#</a></h2><ol><li><p>ZK提供了多层级的节点命名空间，与文件系统不同的是，这些节点都可以设置关联的数据，而文件系统中只有文件节点可存放数据而目录节点不行。</p></li><li><p>ZK保证高吞吐和低延迟，在内存中维护这个树状的目录结构，这个特性使得ZK不能用于存放大量的数据，每个节点的存放数据上限为1M。</p></li></ol><h2 id="_03-zab协议" tabindex="-1">03 ZAB协议 <a class="header-anchor" href="#_03-zab协议" aria-hidden="true">#</a></h2><blockquote><p>ZAB协议是为分布式协调服务设计的一种支持崩溃恢复的原子广播协议。</p></blockquote><ul><li>崩溃恢复及消息广播。当整个ZK集群刚启动或Leader服务器宕机、重启或网络故障，导致不存在过半的服务器与Leader服务器保持正常通信时，所有进程进入崩溃恢复模式，首先选举产生新的Leader服务器，然后集群中Follower服务器开始与新的Leader服务器进行数据同步，当集群中超过半数机器与该Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader服务器开始接收客户端的事务请求生成事务提案来进行事务请求处理。</li></ul><h2 id="_04-znode" tabindex="-1">04 ZNode <a class="header-anchor" href="#_04-znode" aria-hidden="true">#</a></h2><ul><li><p>PERSISTENT 持久节点。除非手动删除，否则节点一直存在于ZK上。</p></li><li><p>EPHEMERAL 临时节点。临时节点的生命周期与客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</p></li><li><p>PERSISTENT SEQUENTIAL 持久顺序节点。基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</p></li><li><p>EPHEMERAL SEQUENTIAL 临时顺序节点。基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。</p></li></ul><h2 id="_05-watcher-机制" tabindex="-1">05 Watcher 机制 <a class="header-anchor" href="#_05-watcher-机制" aria-hidden="true">#</a></h2><p>ZK允许客户端向服务端的某个Znode注册一个Watcher监听，当服务端的一些指定事件触发这个Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据Watcher通知状态和事件类型做出业务上的改变。</p><p>Watcher特性</p><ul><li><p>一次性</p><ul><li>无论是服务端还是客户端，一旦一个Watcher被触发，ZK都会将其从相应的存储中移除。这样的设计有效的减轻了服务器的压力，不然对于更新非常频繁的节点，服务端会不断的向客户端发送事件通知。</li></ul></li><li><p>客户端串行执行</p><ul><li>客户端Watcher回调的过程是一个串行同步的过程。</li></ul></li><li><p>轻量</p><ul><li>Watcher通知非常简单，只会告诉客户端发生了事件，不会说明事件的具体内容。</li><li>客户端向服务端注册Watcher的时候，并不会把客户端真实的Watcher对象实体传递到服务端，仅仅是客户端请求中使用boolean类型属性进行标记。</li></ul></li><li><p>ZK只保证最终的一致性，而无法保证强一致性</p><ul><li>watcher event异步发送watcher的通知事件从server发送到client是异步的，这存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于网络延迟或其他因素导致客户端在不同的时刻监听到事件，由于ZK本身提供了ordering guarantee，即客户端监听事件后才会感知它所监视znode发生了变化。</li></ul></li></ul><blockquote><p>当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发。当与一个服务器失去连接的时候，是无法接收到watch的，而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册，通常这是完全透明的，只有在一个特殊情况下，watch可能会丢失，对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况，watch事件可能会被丢失。</p></blockquote><h2 id="_06-队列管理" tabindex="-1">06 队列管理 <a class="header-anchor" href="#_06-队列管理" aria-hidden="true">#</a></h2><ul><li>同步队列。当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达</li></ul><div class="tip custom-block"><p class="custom-block-title">队列按照FIFO方式入队和出队操作</p><ul><li><p>在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。</p></li><li><p>和分布式锁服务中的控制时序场景基本原理一致，入列有编号。出列按编号，在特定的目录下创建PERSISTENT SEQUENTIAL节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费，此场景下ZK的Znode用于消息存储，Znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的，不必担心队列消息的丢失问题。</p></li></ul></div><h2 id="_07-zookeeper-定义" tabindex="-1">07 zookeeper 定义 <a class="header-anchor" href="#_07-zookeeper-定义" aria-hidden="true">#</a></h2><ol><li>一个分布式的，开放源码的分布式应用程序协调服务</li><li>集群的管理者，监视着集群中各个节点的状态根据节点提交的反馈进行下一步合理操作</li><li>客户端的读请求，可以被集群中的任意一台机器处理，如果读取请求在节点上注册了监听器，这个监听器也是由zk处理的。</li><li>客户端的写请求，这些请求会同时发给其他zk机器并且达成一致后，请求才会返回成功</li><li>zk有序性，所有的更新都是全局有序的，每个更新都有一个唯一的时间戳，这个时间戳称为zxid（zookeeper transaction id），而读请求只会相对于更新有序，读请求的返回结果中会带这个zk最新的zxid</li></ol><h2 id="_08-zk提供服务" tabindex="-1">08 zk提供服务 <a class="header-anchor" href="#_08-zk提供服务" aria-hidden="true">#</a></h2><ol><li>文件系统</li><li>通知机制</li></ol><h2 id="_09-zk文件系统" tabindex="-1">09 zk文件系统 <a class="header-anchor" href="#_09-zk文件系统" aria-hidden="true">#</a></h2><ol><li>zk提供一个多层级的节点命名空间（znode），与文件系统不同的是，这些节点都可设置关联的数据，而文件系统中只有文件节点可以存放数据而目录节点不行。</li><li>zk保证高吞吐和低延迟，在内存中维护了这个树状的目录结构，这些特性使得zk不能用于存放大量数据，每个节点的存放数据上限为1M</li></ol><h2 id="_10-四种类型的znode" tabindex="-1">10 四种类型的znode <a class="header-anchor" href="#_10-四种类型的znode" aria-hidden="true">#</a></h2><ol><li>persistent-持久化目录节点，客户端与zk断开连接后，该节点依旧存在</li><li>persistent-sequential-持久化顺序编号目录节点，客户端与zk断开连接后，该节点依旧存在，只是zk给该节点名称进行顺序编号</li><li>ephemeral-临时目录节点，客户端与zk断开连接后，该节点被删除</li><li>ephemeral-sequential-临时顺序编号目录节点，客户端与zk断开连接后，该节点被删除，只是zk给节点名称进行顺序编号</li></ol><h2 id="_11-zk通知机制" tabindex="-1">11 zk通知机制 <a class="header-anchor" href="#_11-zk通知机制" aria-hidden="true">#</a></h2><p>client端会对某个znode建立一个watcher事件，当该znode发生变化时， 这些client会收到zk的通知，然后client可根据znode变化来做出业务上的改变</p><h2 id="_12-zk功能" tabindex="-1">12 zk功能 <a class="header-anchor" href="#_12-zk功能" aria-hidden="true">#</a></h2><ol><li>命名服务</li><li>配置管理</li><li>集群管理</li><li>分布式锁</li><li>队列管理</li></ol><h2 id="_13-zk命名服务" tabindex="-1">13 zk命名服务 <a class="header-anchor" href="#_13-zk命名服务" aria-hidden="true">#</a></h2><ol><li>命名服务是指定的名字来获取资源或者服务的地址</li><li>利用zk创建一个全局的路径，即是唯一路径</li><li>这个路径就可以作为一个名字，指向集群中的集群，提供服务地址，或者一个远程的对象</li></ol><h2 id="_14-zk配置管理" tabindex="-1">14 zk配置管理 <a class="header-anchor" href="#_14-zk配置管理" aria-hidden="true">#</a></h2><ul><li>程序分布式的部署在不同的机器上，将程序的配置信息放在zk的znode下，</li><li>当有配置发生改变时，也就是znode发生变化时，可通过改变zk中的某个目录节点的内容，</li><li>利用watcher通知给各个客户端，从而更改配置</li></ul><h2 id="_15-zk集群管理" tabindex="-1">15 zk集群管理 <a class="header-anchor" href="#_15-zk集群管理" aria-hidden="true">#</a></h2><ol><li>所谓集群管理：是否有机器退出和加入，选举master</li><li>所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息，一旦有机器挂掉，该机器与zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除了</li><li>所有机器收到通知：新兄弟目录加入，highcount又有了，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好</li></ol><h2 id="_16-zk分布式锁" tabindex="-1">16 zk分布式锁 <a class="header-anchor" href="#_16-zk分布式锁" aria-hidden="true">#</a></h2><ol><li>将zk上的znode看作是一把锁，通过createznode的方式来实现，所有客户端都去创建/distribute_lock节点，最终成功创建的那个客户端也即拥有了这把锁，用完删除掉自己创建的distribute_lock节点就释放出锁</li><li>/distribute_lock已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便</li></ol><h2 id="_17-获取分布式锁的流程" tabindex="-1">17 获取分布式锁的流程 <a class="header-anchor" href="#_17-获取分布式锁的流程" aria-hidden="true">#</a></h2><ol><li>获取分布式锁的时候在locker节点下创建临时顺序节点，释放锁的时候删除该临时节点，客户端调用createNode方法在locker下创建临时顺序节</li><li>调用getChildren（”locker“）来获取locker下面的所有子节点，此时不用设置任何watcher。客户端获取到所有的子节点path之后，如果发现自己创建的子节点序号最小，那么就认为该客户端获取到了锁，如果发现自己创建的节点并非locker所有子节点中最小的，说明自己还没有获取到锁，此时客户端需要找到比自己小的那个节点，然后对其exist（）方法，同时对其注册事件监听器，之后，让这个被关注的节点删除，则客户端的watcher会收到相应通知，此时再次判断自己创建的节点是否是locker子节点中序号最小的，如果是则获取到了锁，如果不是则重复以上步骤继续获取比自己小的一个节点并注册监听，这个过程中还需要许多的逻辑判断</li><li>获取分布式锁的重点逻辑在于BaseDistributedLock，实现了基于zookeeper实现分布式锁的细节</li></ol><h2 id="_18-zk队列管理" tabindex="-1">18 zk队列管理 <a class="header-anchor" href="#_18-zk队列管理" aria-hidden="true">#</a></h2><ol><li>同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。</li><li>队列按照FIFO方式进行入队和出队操作 <ul><li>a. 第一类，在约定目录下创建临时目录节点，监听节点数据是否是我们要求的数目</li><li>b. 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号，在特定的目录下创建persistent_sequential节点，创建成功时watcher通知等待的队列，队列删除序号最小的节点用以消费，此场景下zk的znode用于消息存储，znode存储的数据就是消息队列中的消息内容，sequential序列号就是消息的编号，按序取出即可，由于创建的节点是持久化的，不必担心队列消息的丢失问题</li></ul></li></ol><h2 id="_19-zookeeper的数据模型" tabindex="-1">19 zookeeper的数据模型 <a class="header-anchor" href="#_19-zookeeper的数据模型" aria-hidden="true">#</a></h2><ol><li>共享的树形结构，由一系列的 ZNode数据节点组成，类似文件系统(目录不能存数据）。</li><li>ZNode存有数据信息，如版本号等等。</li><li>ZNode之间的层级关系，像文件系统中的目录结构一样。它是将数据存在内存中提高吞吐减少延迟。</li></ol><h2 id="_20-如何识别请求的先后顺序" tabindex="-1">20 如何识别请求的先后顺序 <a class="header-anchor" href="#_20-如何识别请求的先后顺序" aria-hidden="true">#</a></h2><p>zookeeper会给每个更新请求，分配一个全局唯一的递增编号（zxid)，编号的大小体现事务操作的先后顺序。</p><h2 id="_21-znode的类型" tabindex="-1">21 ZNode的类型 <a class="header-anchor" href="#_21-znode的类型" aria-hidden="true">#</a></h2><ul><li>持久节点：一旦创建，除非主动移除，否则会一直保存在zookeeper。</li><li>临时节点：生命周期和客户端会话绑定，会话失效，相关的临时节点被移除。</li></ul><h2 id="_21-zookeeper定义了几种权限" tabindex="-1">21 zookeeper定义了几种权限 <a class="header-anchor" href="#_21-zookeeper定义了几种权限" aria-hidden="true">#</a></h2><ul><li>CREATE</li><li>READ</li><li>WRITE</li><li>DELETE</li><li>ADMIN</li></ul><h2 id="_22-zab" tabindex="-1">22 ZAB <a class="header-anchor" href="#_22-zab" aria-hidden="true">#</a></h2><ul><li>全称 zookeeper Atomic Broadcast （zookeeper原子广播）</li><li>zookeeper 是通过 Zab 协议来保证分布式事务的最终一致性。是一种支持崩溃恢复的原子广播协议。</li></ul><div class="tip custom-block"><p class="custom-block-title">ZAB有两种基本模式</p><ul><li><strong>崩溃恢复</strong>：在正常情况下运行非常良好，一旦Leader出现崩溃或者由于网络原因导致Leader服务器失去了与过半Follower的联系，那么就会进入崩溃恢复模式。为了程序的正确运行，整个恢复过程后需要选举出一个新的Leader,因此需要一个高效可靠的选举方法快速选举出一个Leader。</li><li><strong>消息广播</strong>：类似一个两阶段提交过程，针对客户端的事务请求， Leader服务器会为其生成对应的事务Proposal,并将其发送给集群中的其余所有机器，再分别收集各自的选票，最后进行事务提交。</li></ul></div><h2 id="_23-什么情况会导致zab进入崩溃恢复模式并选取出新的leader" tabindex="-1">23 什么情况会导致ZAB进入崩溃恢复模式并选取出新的leader <a class="header-anchor" href="#_23-什么情况会导致zab进入崩溃恢复模式并选取出新的leader" aria-hidden="true">#</a></h2><ol><li>启动过程或leader出现网络中断 崩溃退出与重启等异常情况时。</li><li>当选举出新的leader后，同时集群中已有过半的机器与该Leader服务器完成了状态同步之后，ZAB就会退出恢复模式。</li></ol><div class="language-shell"><span class="copy"></span><pre><code><span class="line"><span style="color:#C9D1D9;">13. </span><span style="color:#8B949E;">## 09 如何创建一个Znode</span></span>
<span class="line"><span style="color:#C9D1D9;">    create -e或者-s /aaa </span><span style="color:#A5D6FF;">&quot;bbb&quot;</span></span>
<span class="line"><span style="color:#C9D1D9;">    </span><span style="color:#8B949E;">## 10 如何获取指定节点信息</span></span>
<span class="line"><span style="color:#C9D1D9;">    get /aaa</span></span>
<span class="line"><span style="color:#C9D1D9;">    </span><span style="color:#8B949E;">## 11 如何查看子节点信息</span></span>
<span class="line"><span style="color:#C9D1D9;">    ls /aaa</span></span>
<span class="line"><span style="color:#C9D1D9;">    </span><span style="color:#8B949E;">## 12 如何更新指定节点信息</span></span>
<span class="line"><span style="color:#C9D1D9;">    </span><span style="color:#79C0FF;">set</span><span style="color:#C9D1D9;"> /aaa </span><span style="color:#A5D6FF;">&quot;ccc&quot;</span></span>
<span class="line"><span style="color:#C9D1D9;">    </span><span style="color:#8B949E;">#如何删除指定节点</span></span>
<span class="line"><span style="color:#C9D1D9;">    delete /aaa</span></span>
<span class="line"></span></code></pre></div><h2 id="_24-watch监听器" tabindex="-1">24 watch监听器 <a class="header-anchor" href="#_24-watch监听器" aria-hidden="true">#</a></h2><p>zookeeper允许用户在指定节点上注册Watcher,当触发特定事件时， zookeeper服务端会把相应的事件通知到相应的客户端上，属于zookeeper一个重要的特性。</p><div class="language-shell"><span class="copy"></span><pre><code><span class="line"><span style="color:#C9D1D9;">get /aaa watch 监控节点变化</span></span>
<span class="line"></span></code></pre></div><h2 id="_25-客户端如何获取配置信息" tabindex="-1">25 客户端如何获取配置信息 <a class="header-anchor" href="#_25-客户端如何获取配置信息" aria-hidden="true">#</a></h2><p>启动时主动到服务端拉取信息，同时，在制定节点注册Watcher监听。 一旦有配置变化，服务端就会实时通知订阅它的所有客户端。</p><h2 id="_26-zk数据复制" tabindex="-1">26 zk数据复制 <a class="header-anchor" href="#_26-zk数据复制" aria-hidden="true">#</a></h2><p><strong>从客户端读写访问的透明度来看，数据复制集群系统分为下面两种：</strong></p><ol><li>写主：对数据的修改提交给指定的节点，读无此限制，可读取任何一个节点，这种情况下客户端需要对读与写进行区别，俗称读写分离</li><li>写任意：对数据的修改可提交给任意的节点，跟读一样，这种情况下，客户端对集群节点的角色与变化透明 对于zk来说，它采用的方式是写任意，通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降，而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。</li></ol><h2 id="_27-zk工作原理" tabindex="-1">27 zk工作原理 <a class="header-anchor" href="#_27-zk工作原理" aria-hidden="true">#</a></h2><ol><li>zk的核心是原子广播，这个机制保证了各个server之间的同步，实现这个机制的协议叫做zab协议，</li><li>zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步），当服务启动或者在领导者崩溃后，</li><li>zab就进入了恢复模式，当领导者被选举出来，且大多数server完成了和leader的状态同步以后，</li><li>恢复模式就结束了，状态同步保证了leader和server具有相同的系统状态。</li></ol><h2 id="_28-zk如何保证事务的顺序一致性" tabindex="-1">28 zk如何保证事务的顺序一致性 <a class="header-anchor" href="#_28-zk如何保证事务的顺序一致性" aria-hidden="true">#</a></h2><ul><li>zk采用了递增的事务id来标识，所有的proposal（提议）都在被提出的时候加上zxid，</li><li>zxid实际上是一个64位的数字，高32位是epoch用来标识leader是否发生改变，</li><li>如果有新的leader产生出来，epoch会自增，低32位用来递增计数，</li><li>当新产生proposal的时候，会依据数据库的两阶段过程，首先会向其他的server发出事务执行请求，</li><li>如果超过半数的机器都能执行并且能够成功，那么就会开始执行</li></ul><h2 id="_29-zk下server工作状态" tabindex="-1">29 zk下server工作状态 <a class="header-anchor" href="#_29-zk下server工作状态" aria-hidden="true">#</a></h2><p>每个server在过程种有三种状态</p><ul><li>looking：当前server不知道leader是谁，正在搜寻</li><li>leading：当前server即为选举出来的leader</li><li>following：leader已经选举出来，当前server与之同步</li></ul><h2 id="_30-zk是选取leader" tabindex="-1">30 zk是选取leader <a class="header-anchor" href="#_30-zk是选取leader" aria-hidden="true">#</a></h2><p>当leader崩溃或者leader失去大多数的follower，这时zk进入恢复模式，恢复模式需要重新选举出一个新的leader，让所有的server都恢复到一个正确的状态</p><p>zk的选举算法</p><ul><li>一种基于basic paxos实现的</li><li>一种基于fast paxos算法实现的</li><li>系统默认选举算法为fast paxos</li></ul><h2 id="_31-zk选主流程" tabindex="-1">31 zk选主流程 <a class="header-anchor" href="#_31-zk选主流程" aria-hidden="true">#</a></h2><ul><li>a. 选举线程由当前server发起选举的线程担任，其主要功能是对投票结果进行统计，并选出推荐的server</li><li>b. 选举线程首先向所有server发起一次询问</li><li>c. 选举线程收到回复后，验证是否是自己发起的询问（验证zxid是否一致），然后获取对方的id(myid)，并存储到当前询问对象列表中，最后获取对方提议的leader相关信息（id，zxid）,并将这些信息存储到当次选举的投票记录表中</li><li>d. 收到所有server回复以后，就计算出zxid最大的那个server，并将这个server相关信息设置成下一次要投票的server</li><li>e. 线程将当前zxid最大的server设置为当前server要推荐leader，如果此时获胜的server获取n/2 + 1 的Server票数，设置当前推荐的leader为获取server，将根据获取的server相关信息设置自己的状态，否则，继续这个过程，直到leader选举出来，通过流程分析我们可以得出：要使leader获得多数server的支持，则server总数必须是奇数2n+1，且存活的server的数目不得少于n+1，每个server启动后都会重复以上流程，在恢复模式下，如果是刚从崩溃状态恢复或者刚启动的server还会磁盘快照中恢复数据和会话信息，zk会记录事务日志并定期进行快照，方便在恢复时进行状态恢复</li></ul><h2 id="_32-zk选主流程" tabindex="-1">32 zk选主流程 <a class="header-anchor" href="#_32-zk选主流程" aria-hidden="true">#</a></h2><ul><li>fast paxos流程是在选举过程中，某server首先向所有server提议自己要成为leader，</li><li>当其它server收到提议以后，解决epoch和zxid的冲突，并接受对方的提议，</li><li>然后向对方发送接受提议完成的消息，重复这个流程，最后一定选举出leader</li></ul><h2 id="_33-zk同步流程" tabindex="-1">33 zk同步流程 <a class="header-anchor" href="#_33-zk同步流程" aria-hidden="true">#</a></h2><ol><li>选完leader以后，zk就进入状态同步过程</li><li>leader等待server链接</li><li>follower链接leader，将最大的zxid发送给leader</li><li>leader根据follower的zxid确定同步点</li><li>完成同步后通知follower已经成为uptodate状态</li><li>follower收到uptodate消息后，又可以重新接受client的请求进行服务了</li></ol><h2 id="_34-分布式通知和协调" tabindex="-1">34 分布式通知和协调 <a class="header-anchor" href="#_34-分布式通知和协调" aria-hidden="true">#</a></h2><ul><li>对于系统调度来说：操作人员发送通知实际是通过控制台改变某个节点的状态，</li><li>然后zk将这些变化给注册了这个节点的watcher的所有客户端</li><li>每个工作进程都在某个目录下创建一个临时节点，并携带工作的进度数据，</li><li>这样汇总的进程可监控目录子节点的变化获得工作进度的实时的全局情况</li></ul><h2 id="_35-机器中leader" tabindex="-1">35 机器中leader <a class="header-anchor" href="#_35-机器中leader" aria-hidden="true">#</a></h2><p>分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果， 这样可大大减少重复计算，提高性能，于是就需要进行leader选举</p><h2 id="_36-zk节点宕机如何处理" tabindex="-1">36 zk节点宕机如何处理 <a class="header-anchor" href="#_36-zk节点宕机如何处理" aria-hidden="true">#</a></h2><ol><li>zk本身也是集群，推荐配置不少于3个服务器，zk自身也保证当一个节点宕机时，其他节点会继续提供服务</li><li>如果是一个follower宕机，还有2台服务器提供访问，因为zk上的数据是有多个副本的，数据并不会丢失</li><li>如果一个leader宕机，zk会选举出新的leader</li><li>zk集群的机制只要超多半数的节点正常，集群就可正常提供服务，只有在zk节点挂太多，只剩一半或不到一半节点能工作，集群才失效。</li></ol><h2 id="_37-zk-watch机制" tabindex="-1">37 zk watch机制 <a class="header-anchor" href="#_37-zk-watch机制" aria-hidden="true">#</a></h2><p><strong>watch机制官方声明：一个watch事件是一个一次性的触发器，当被设置了watch的数据发生了改变时， 则服务器将这个改变发送给设置了watch的客户端，以便通知它们</strong></p><ol><li>一次性触发数据发生改变时，一个watcher event会被发送到client，但是client只会收到一次这样的信息。</li><li>watcher event异步发送watcher的通知事件从server发送到client时异步的，这就存在了一个文件，不同的客户端和服务器socket进行通信，由于网络延迟或其他因素导致客户端在不同的时刻监听到事件，由于zk本身提供了ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化，我们使用zk不能期望能够监控到节点，每次的变化，zk只能保证最终的一致性，而无法保证强一致性。</li><li>数据监控zk有数据监视和子数据监视getdata() and exists()设置了数据监视，getchildren()设置了子节点监视，</li><li>注册watcher getData、exists、getChildren</li><li>触发watcher （create、delete、setData）</li><li>setData()会触发znode上设置的data watch（如果set成功的话）。一个成功的create()操作触发被创建的znode上数据watch，以及其父节点上的child watch，而一个成功的delete()操作将会同时触发一个znode的data watch和child watch（因为这样就没子节点了），同时也会触发其父节点的child watch</li><li>当一个客户端连接到一个新的服务器上时，watch将会被以任意会话事件触发，当与一个服务器失去连接的时候，是无法接收到watch的，而当client重新连接时，如果需要的话，所有先前注册过的watch，都会被重新注册，通常这是完全透明的，只有在一个特定情况下，watch可能会丢失，对于一个未创建的znode的exist watch，如果在客户端断开连接期间被创建了，并且随后在客户端连接上之前又删除了，这种情况下，这个watch事件可能会被丢失</li><li>watch是一个轻量级的，其实就是本地jvm的callback，服务器只是存了是否有设置了watcher的布尔类型</li></ol><h2 id="_38-zk对节点的watch监听通知是永久的吗" tabindex="-1">38 zk对节点的watch监听通知是永久的吗 <a class="header-anchor" href="#_38-zk对节点的watch监听通知是永久的吗" aria-hidden="true">#</a></h2><ol><li>不是永久的，一个watch事件是一个一次性的触发器，当被设置了watch的数据发生了改变的时候，则服务器将这个改变发送给设置了watch的客户端，以便通知它们</li><li>如果服务端变动频繁，而监听的客户端很多情况下，每次变动都要通知到所有的客户端，给网络和服务器造成很大的压力，一般客户端执行getData（&quot;/节点A&quot;，true），如果节点A发生了变更或删除，客户端会得到它的watch事件，但是在之后节点A又发生了变更，而客户端又没有设置watch事件，就不再给客户端发送</li></ol><h2 id="_39-zab和paxos算法" tabindex="-1">39 zab和paxos算法 <a class="header-anchor" href="#_39-zab和paxos算法" aria-hidden="true">#</a></h2><ol><li>两者存在一个类似于leader进程的角色，由其负责协调多个follower进程的运行</li><li>leader进程都会等待超过半数的follower做出正确的反馈后，才将一个提案进行提交</li><li>zab协议中，每个proposal中都包含一个epoch值来代表当前的leader周期，paxos中名字为ballot</li><li>zab用来构建高可用的分布式数据主备系统，paxos是用来构建分布式一致性状态机系统</li></ol><h2 id="_40-nginx如何处理http请求" tabindex="-1">40 Nginx如何处理HTTP请求 <a class="header-anchor" href="#_40-nginx如何处理http请求" aria-hidden="true">#</a></h2><ol><li>首先Nginx在启动时，会解析配置文件，得到需要监听的端口与IP地址，</li><li>然后在Nginx的Master进程里面先初始化好这个监控Socket，再fork出多个子进程出来</li><li>子进程会竞争accept新的连接，此时，客户端可向nginx发起连接了，当客户端与nginx进行三次握手，与nginx建立好一个连接后，此时某个子进程会accept成功，得到这个建立好的连接的socket，然后创建nginx对连接的封装，即ngx_connection_t结构体</li><li>设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换</li></ol><h2 id="_41-nginx高并发" tabindex="-1">41 Nginx高并发 <a class="header-anchor" href="#_41-nginx高并发" aria-hidden="true">#</a></h2><ol><li>Nginx的异步非阻塞工作方式，正是利用了这点等待的时间，在需要等待的时候，这些进程就空闲出来待命了</li><li>Nginx采用单线程来异步非阻塞处理请求，不会为每个请求分配cpu和内存资源，节省了大量资源，同时减少大量cpu的上下文切换</li></ol><h2 id="_42-内存屏障" tabindex="-1">42 内存屏障 <a class="header-anchor" href="#_42-内存屏障" aria-hidden="true">#</a></h2><p>现代操作系统都是多处理器操作系统，每个处理器都会有自己的缓存，可能存在不同处理器缓存不一致的问题，而且由于操作系统可能存在重排序，导致读取到错误的数据，因此操作提供一些内存屏障以解决这种问题</p><ul><li>LoadLoad屏障 对于Load1;LoadLoad;Load2，操作系统保证在Load2及后续的读操作读取之前，Load1已经读取</li><li>StoreStore屏障 对于Store1;StoreStore;Store2，操作系统保证在Store2及后续的写操作写入之前，Store已经写入</li><li>LoadStore屏障 对于Load1;LoadStore;Store2，操作系统保证在Store2及后续写入操作执行前，Load1已经读取。</li><li>StoreLoad屏障 对于Store1;StoreLoad;Load2，操作系统保证在Load2及后续读取操作执行前，Store已经写入，开销较大，但是同时具备其他三种屏障的效果</li></ul><ol><li>当我们声明某个变量为volatile时，这个变量便具有了线程可见性，volatile通过读写操作前后添加内存屏障，完成了数据的及时可见性</li><li>当写入一个volatile变量时，jmm会把该线程对应的本地内存中的共享变量刷新到主内存，当读一个volatile变量时，jmm会把该线程对应的本地内存置为无效，从主内存读取所有的共享变量。</li><li>volatile读之前，会添加LoadLoad内存屏障，读之后会加LoadStore内存屏障，写之前会加StoreStore内存屏障，写之后会添加StoreLoad内存屏障</li></ol><h2 id="_43-zookeeper-功能" tabindex="-1">43 zookeeper 功能 <a class="header-anchor" href="#_43-zookeeper-功能" aria-hidden="true">#</a></h2><ul><li>集群管理：监控节点存活状态、运行请求等。</li><li>主节点选举：主节点挂掉了之后可以从备用的节点开始新一轮选主，主节点选举说的就是这个选举的过程，使用 zookeeper 可以协助完成这个过程。</li><li>分布式锁：zookeeper 提供两种锁：独占锁、共享锁。独占锁即一次只能有一个线程使用资源，共享锁是读锁共享，读写互斥，即可以有多线线程同时读同一个资源，如果要使用写锁也只能有一个线程使用。</li><li>zookeeper可以对分布式锁进行控制。</li><li>命名服务：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。</li></ul><h2 id="_44-zookeeper-有几种部署模式？" tabindex="-1">44 zookeeper 有几种部署模式？ <a class="header-anchor" href="#_44-zookeeper-有几种部署模式？" aria-hidden="true">#</a></h2><p><strong>zookeeper 有三种部署模式：</strong></p><ul><li>单机部署：一台集群上运行；</li><li>集群部署：多台集群运行；</li><li>伪集群部署：一台集群启动多个zookeeper 实例运行。</li></ul><h2 id="_45-zookeeper-怎么保证主从节点的状态同步？" tabindex="-1">45 zookeeper 怎么保证主从节点的状态同步？ <a class="header-anchor" href="#_45-zookeeper-怎么保证主从节点的状态同步？" aria-hidden="true">#</a></h2><ol><li>zookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 zab 协议。</li><li>zab 协议有两种模式，分别是恢复模式（选主）和广播模式（同步）。</li><li>当服务启动或者在领导者崩溃后，zab 就进入了恢复模式，当领导者被选举出来， 且大多数 server 完成了和 leader 的状态同步以后，恢复模式就结束了。 状态同步保证了 leader 和 server 具有相同的系统状态。</li></ol><h2 id="_46-集群中为什么要有主节点？" tabindex="-1">46 集群中为什么要有主节点？ <a class="header-anchor" href="#_46-集群中为什么要有主节点？" aria-hidden="true">#</a></h2><p>在分布式环境中，有些业务逻辑只需要集群中的某一台机器进行执行，其他的机器可以共享这个结果， 这样可以大大减少重复计算，提高性能，所以就需要主节点。</p><h2 id="_47-集群中有-3-台服务器，其中一个节点宕机，这个时候-zookeeper-还可以使用吗？" tabindex="-1">47 集群中有 3 台服务器，其中一个节点宕机，这个时候 zookeeper 还可以使用吗？ <a class="header-anchor" href="#_47-集群中有-3-台服务器，其中一个节点宕机，这个时候-zookeeper-还可以使用吗？" aria-hidden="true">#</a></h2><p>可以继续使用，单数服务器只要没超过一半的服务器宕机就可以继续使用。</p><h2 id="_48-zookeeper-通知机制" tabindex="-1">48 zookeeper 通知机制 <a class="header-anchor" href="#_48-zookeeper-通知机制" aria-hidden="true">#</a></h2><p>客户端端会对某个znode 建立一个 watcher 事件，当该 znode 发生变化时， 这些客户端会收到 zookeeper 的通知，然后客户端可以根据 znode 变化来做出业务上的改变。</p><h2 id="_49-zk-对节点的-watch-监听通知是永久的吗" tabindex="-1">49 zk 对节点的 watch 监听通知是永久的吗 <a class="header-anchor" href="#_49-zk-对节点的-watch-监听通知是永久的吗" aria-hidden="true">#</a></h2><p>不是永久的，一个 watch 事件是一个一次性的触发器，当被设置了 watch 的数据发生了改变的时候， 则服务器将这个改变发送给设置了 watch 的客户端，以便通知它们。</p><p>如果服务端变动频繁，而监听的客户端很大情况下，每次变动都要通知到所有的客户端，给网络和服务器造成 很大的压力，一般客户端执行 getData (&quot;/节点A&quot;, true)，如果节点 A 发生了变更或删除，客户端会得到它的 watch 事件，但是在之后节点 A 又发生了变更，而客户端又没有设置 watch 事件，就不再给客户端发送了。</p><h2 id="_50-zab-和-paxos-算法" tabindex="-1">50 zab 和 paxos 算法 <a class="header-anchor" href="#_50-zab-和-paxos-算法" aria-hidden="true">#</a></h2><ol><li>两者存在一个类似于 leader 进程的角色，由其负责协调多个 follower 进程的运行。</li><li>leader 进程都会等待超过半数的 follower 做出正确的反馈后，才将一个提案进行提交。</li><li>zab 协议中，每个 proposal 中都包含一个 epoch 值来代表当前的 leader 周期，paxos 中名字为 ballot</li><li>zab 用来构建高可用的分布式数据主备系统，paxos 是用来构建分布式一致性状态机系统。</li></ol><h2 id="_51-nginx-如何处理-http-请求" tabindex="-1">51 nginx 如何处理 http 请求 <a class="header-anchor" href="#_51-nginx-如何处理-http-请求" aria-hidden="true">#</a></h2><ol><li>首先，nginx 在启动时，会解析配置文件，得到需要监听的端口与 ip 地址，</li><li>然后在 nginx 的 master 进程里面先初始化好这个监控 socket</li><li>再 fork 出多个子进程出来，子进程会竞争 accept 新的连接，</li><li>此时，客户端可向 nginx 发起连接了，当客户端与 nginx 进行三次握手，</li><li>与 nginx 建立好一个连接后，此时某个子进程会 accept 成功，得到这个建立好的连接的 socket，</li><li>然后创建 nginx 对连接的封装，即 ngx_connection_t 结构体，</li><li>设置读写事件处理函数，并添加读写事件来与客户端进行数据的交换。</li></ol><h2 id="_52-nginx-高并发" tabindex="-1">52 nginx 高并发 <a class="header-anchor" href="#_52-nginx-高并发" aria-hidden="true">#</a></h2><ol><li>nginx 的异步阻塞工作方式，正是利用了这点等待的时间，在需要等待的时候，这些进程就空闲出来待命了。</li><li>nginx 采用单线程来异步非阻塞处理请求，不会为每个请求分配 cpu 和内存资源，</li><li>节省了大量的资源，同时减少了大量 cpu 的上下文切换。</li></ol><h2 id="_53-内存屏障" tabindex="-1">53 内存屏障 <a class="header-anchor" href="#_53-内存屏障" aria-hidden="true">#</a></h2><ol><li>现代操作系统都是多处理器操作系统，每个处理器都会有自己的缓存，可能存在不同处理器缓存不一致的问题，</li><li>而且由于操作系统可能存在重排序，导致读取到错误的数据，因此操作提供了一些内存屏障以解决这种问题。</li></ol><div class="tip custom-block"><p class="custom-block-title">LoadLoad 屏障</p><p>对于 Load1;LoadLoad;Load2，操作系统保证在 Load2 及后续的读操作读取之前，Load1 已经读取</p></div><div class="tip custom-block"><p class="custom-block-title">StoreStore 屏障</p><p>对于 Store1;StoreStore;Store2，操作系统保证在 Store2 及后续的写操作写入之前，Store1已经写入。</p></div><div class="tip custom-block"><p class="custom-block-title">LoadStore 屏障</p><p>对于 Load1;LoadStore;Store2，操作系统保证在 Store2 及后续写入操作执行前，Load1 已经读取。</p></div><div class="tip custom-block"><p class="custom-block-title">StoreLoad 屏障</p><p>对于 Store1;StoreLoad;Load2，操作系统保证在 Load2 及后续读取操作执行前，Store1 已经写入，开销较大，但是同时 具备其他三种屏障的效果</p></div><ol start="3"><li><p>当我们声明某个变量为 volatile 时，这个变量便具有了线程可见性，volatile 通过读写操作前后添加内存屏障， 完成了数据的及时可见性。</p></li><li><p>当写入一个 volatile 变量时，jmm 会把该线程对应的本地内存中的共享变量刷新到主内存，</p></li><li><p>当读一个 volatile 变量时，jmm 会把该线程对应的本地内存置为无效，从主内存读取所有的共享变量</p></li><li><p>volatile 读之前，会添加 LoadLoad 内存屏障，读之后会加 LoadStore 内存屏障，写之前会加 StoreStore 内存屏障，写 之后会添加 StoreLoad 内存屏障。</p></li></ol><h2 id="_54-柔性事务" tabindex="-1">54 柔性事务 <a class="header-anchor" href="#_54-柔性事务" aria-hidden="true">#</a></h2><p>柔性事务是相对强制锁表的刚性事务而言</p><div class="tip custom-block"><p class="custom-block-title">流程如下：</p><ul><li>服务器 A 的事务如果执行顺利，那么事务 A 就先行提交，如果事务 B 也执行顺利，则事务 B 也提交，整个事务就算完成。</li><li>但是如果事务 B 执行失败，事务 B 本身回滚，这时事务 A 已经被提交，所以需要执行一个补偿操作</li><li>将已经提交的事务 A 执行的操作作反操作，恢复到未执行前事务 A 的状态。</li></ul></div><div class="danger custom-block"><p class="custom-block-title">缺点</p><ul><li>业务侵入性太强，还要补偿操作，缺乏普遍性，没法大规模推广</li></ul></div><h2 id="_55-zookeeper-实现分布式锁" tabindex="-1">55 zookeeper 实现分布式锁 <a class="header-anchor" href="#_55-zookeeper-实现分布式锁" aria-hidden="true">#</a></h2><ol><li>客户端对某个方法加锁时，在zk上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点node1</li><li>客户端获取该路径下所有已经创建的子节点，如果发现自己创建的node1的序号是最小的，就认为这个客户端获得了锁</li><li>如果发现node1不是最小的，则监听比自己创建节点序号小的最大的节点，进入等待</li><li>获取锁后，处理完逻辑，删除自己创建的node1即可</li></ol><blockquote><p>zk性能差一些，开销大，实现简单</p></blockquote></div></div></main><footer class="VPDocFooter" data-v-3886f8ec data-v-4fc1a8f4><div class="edit-info" data-v-4fc1a8f4><div class="edit-link" data-v-4fc1a8f4><a class="VPLink link edit-link-button" href="https://github.com/space2030?tab=repositories" target="_blank" rel="noopener noreferrer" data-v-4fc1a8f4 data-v-8dd034e6><!--[--><svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24" class="edit-link-icon" data-v-4fc1a8f4><path d="M18,23H4c-1.7,0-3-1.3-3-3V6c0-1.7,1.3-3,3-3h7c0.6,0,1,0.4,1,1s-0.4,1-1,1H4C3.4,5,3,5.4,3,6v14c0,0.6,0.4,1,1,1h14c0.6,0,1-0.4,1-1v-7c0-0.6,0.4-1,1-1s1,0.4,1,1v7C21,21.7,19.7,23,18,23z"></path><path d="M8,17c-0.3,0-0.5-0.1-0.7-0.3C7,16.5,6.9,16.1,7,15.8l1-4c0-0.2,0.1-0.3,0.3-0.5l9.5-9.5c1.2-1.2,3.2-1.2,4.4,0c1.2,1.2,1.2,3.2,0,4.4l-9.5,9.5c-0.1,0.1-0.3,0.2-0.5,0.3l-4,1C8.2,17,8.1,17,8,17zM9.9,12.5l-0.5,2.1l2.1-0.5l9.3-9.3c0.4-0.4,0.4-1.1,0-1.6c-0.4-0.4-1.2-0.4-1.6,0l0,0L9.9,12.5z M18.5,2.5L18.5,2.5L18.5,2.5z"></path></svg> 在 github 上编辑此页<!--]--><!----></a></div><div class="last-updated" data-v-4fc1a8f4><p class="VPLastUpdated" data-v-4fc1a8f4 data-v-537b088a>最后更新: <time datatime="2023-10-19T07:32:22.000Z" data-v-537b088a></time></p></div></div><!----></footer><!--[--><!--]--></div></div></div></div></div><footer class="VPFooter" data-v-581d5782 data-v-3d0cd5b8><div class="container" data-v-3d0cd5b8><p class="message" data-v-3d0cd5b8>Released under the MIT License.</p><p class="copyright" data-v-3d0cd5b8>Copyright © 2023-present Evan You</p></div></footer><!--[--><!--]--></div></div>
    <script>__VP_HASH_MAP__ = JSON.parse("{\"index.md\":\"f37252e3\",\"src_case_example_aqs抽象队列同步器.md\":\"24756237\",\"src_case_example_arraylist扩容机制解析.md\":\"a4b8bed3\",\"src_case_example_arrays类sort()方法使用的排序算法.md\":\"ccfbb6ab\",\"src_case_example_concurrenthashmap为什么放弃了分段锁.md\":\"0a4ffee0\",\"src_case_example_es与mysql数据不一致.md\":\"d871661c\",\"src_case_example_redis与mysql数据不一致.md\":\"26418c82\",\"src_case_example_tomcat性能优化.md\":\"dfbb266f\",\"src_case_example_中间件设计.md\":\"468e8da7\",\"src_case_example_代码片段.md\":\"925caa6b\",\"src_case_example_分布式事务解决方案.md\":\"2f070cfb\",\"src_case_example_分布式唯一id.md\":\"23eadd1f\",\"src_case_example_分布式锁-基于数据库的实现.md\":\"4d8b29d2\",\"src_case_example_分库分表.md\":\"c52281c2\",\"src_case_example_如何处理千万级别mysql数据库锁表问题.md\":\"b4c0af50\",\"src_case_example_如何快速从千万级大表删除数据.md\":\"91fe5800\",\"src_case_example_批量处理数据.md\":\"78b0d9bb\",\"src_case_example_接口性能优化.md\":\"9d1792f7\",\"src_case_example_架构设计.md\":\"d307ccb7\",\"src_case_example_百万级别数据导入导出如何优化.md\":\"98a549ab\",\"src_case_example_百万级数据深度分页如何优化.md\":\"32c9674d\",\"src_case_example_秒杀.md\":\"fcad5d18\",\"src_case_example_系统设计规范.md\":\"15c311eb\",\"src_case_example_线上环境踩坑之并行流丢失数据.md\":\"1c3be8f9\",\"src_case_example_线程池.md\":\"e4225766\",\"src_case_example_综合面.md\":\"f493e2fa\",\"src_case_example_网络.md\":\"2753f5be\",\"src_case_example_设计接口.md\":\"38f526c0\",\"src_case_example_设计模式.md\":\"47a4706e\",\"src_case_example_重构.md\":\"f8b1bb82\",\"src_case_index.md\":\"e7293aa9\",\"src_case_norm_javascript规范.md\":\"9fb24129\",\"src_case_norm_java规范.md\":\"538dd69a\",\"src_case_norm_markdown规范.md\":\"2b32c5f2\",\"src_case_norm_vue规范.md\":\"898eb012\",\"src_case_norm_前后端规约.md\":\"e89a40a3\",\"src_case_norm_接口对接规范.md\":\"6d91f32f\",\"src_case_norm_日志规范.md\":\"f59ee845\",\"src_case_redis操作.md\":\"2f51e4c7\",\"src_deploy_index.md\":\"6cb4a725\",\"src_deploy_mongodb部署.md\":\"8a227b4a\",\"src_deploy_mysql部署.md\":\"11af5f81\",\"src_deploy_node部署.md\":\"fdf9e10a\",\"src_deploy_oracle部署.md\":\"f730433a\",\"src_deploy_redis部署.md\":\"ad57b569\",\"src_git_index.md\":\"1f809b9a\",\"src_index_index.md\":\"33da6e30\",\"src_kit_blog.md\":\"1c11ac7e\",\"src_kit_index.md\":\"04dd6794\",\"src_kit_nginx.md\":\"5c165844\",\"src_kit_tool.md\":\"d4ebdde9\",\"src_view_index.md\":\"dc64bfa6\",\"src_view_java_java-01-se.md\":\"d50e6d5e\",\"src_view_java_java-02-ee.md\":\"06cece6f\",\"src_view_java_java-03-tomcat.md\":\"4e071e95\",\"src_view_java_java-04-spring.md\":\"294e3736\",\"src_view_java_java-05-mybatis.md\":\"f08a45bf\",\"src_view_java_java-06-spring-boot.md\":\"0aff5c53\",\"src_view_java_java-07-maven.md\":\"cd8805f9\",\"src_view_java_java-08-spring-cloud.md\":\"9b8482f6\",\"src_view_java_java-09-mysql.md\":\"00f74996\",\"src_view_java_java-10-redis.md\":\"07f078ba\",\"src_view_java_java-11-oracle.md\":\"333de976\",\"src_view_java_java-12-gateway.md\":\"d8b6a793\",\"src_view_java_java-13-elasticsearch.md\":\"b01a920e\",\"src_view_java_java-14-mongodb.md\":\"a29b919f\",\"src_view_java_java-15-rocketmq.md\":\"2983da5e\",\"src_view_java_java-16-activemq.md\":\"d2aa5ffd\",\"src_view_java_java-17-rabbitmq.md\":\"ed854218\",\"src_view_java_java-18-zookeeper.md\":\"2bb8ca84\",\"src_view_java_java-19-kafka.md\":\"ef7bf4c5\",\"src_view_web_web-01-html.md\":\"f76a68db\",\"src_view_web_web-02-javascript.md\":\"560f2ce1\",\"src_view_web_web-03-vue.md\":\"e6cb6cc4\",\"src_web_index.md\":\"4759f761\",\"src_web_vitepress_vitepress快速开始.md\":\"86859a47\",\"src_web_vitepress_vitepress语法规则.md\":\"e4ba6974\",\"src_web_vitepress_vitepress项目发布.md\":\"246085db\"}")</script>
    <script type="module" async src="/vitepress-deploy/assets/app.2a154df8.js"></script>
    
  </body>
</html>